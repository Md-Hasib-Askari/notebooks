{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c210612",
   "metadata": {},
   "source": [
    "### 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ae7f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in e:\\miniconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: xgboost in e:\\miniconda3\\lib\\site-packages (3.0.4)\n",
      "Requirement already satisfied: lightgbm in e:\\miniconda3\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: catboost in e:\\miniconda3\\lib\\site-packages (1.2.8)\n",
      "Requirement already satisfied: scikit-learn in e:\\miniconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: imbalanced-learn in e:\\miniconda3\\lib\\site-packages (0.13.0)\n",
      "Requirement already satisfied: shap in e:\\miniconda3\\lib\\site-packages (0.48.0)\n",
      "Requirement already satisfied: plotly in e:\\miniconda3\\lib\\site-packages (6.3.0)\n",
      "Requirement already satisfied: matplotlib in e:\\miniconda3\\lib\\site-packages (3.10.5)\n",
      "Requirement already satisfied: seaborn in e:\\miniconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: alembic>=1.5.0 in e:\\miniconda3\\lib\\site-packages (from optuna) (1.16.4)\n",
      "Requirement already satisfied: colorlog in e:\\miniconda3\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in e:\\miniconda3\\lib\\site-packages (from optuna) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\miniconda3\\lib\\site-packages (from optuna) (24.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in e:\\miniconda3\\lib\\site-packages (from optuna) (2.0.43)\n",
      "Requirement already satisfied: tqdm in e:\\miniconda3\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in e:\\miniconda3\\lib\\site-packages (from optuna) (6.0.2)\n",
      "Requirement already satisfied: scipy in e:\\miniconda3\\lib\\site-packages (from xgboost) (1.15.3)\n",
      "Requirement already satisfied: graphviz in e:\\miniconda3\\lib\\site-packages (from catboost) (0.21)\n",
      "Requirement already satisfied: pandas>=0.24 in e:\\miniconda3\\lib\\site-packages (from catboost) (2.3.1)\n",
      "Requirement already satisfied: six in e:\\miniconda3\\lib\\site-packages (from catboost) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in e:\\miniconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in e:\\miniconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in e:\\miniconda3\\lib\\site-packages (from imbalanced-learn) (0.1.3)\n",
      "Requirement already satisfied: slicer==0.0.8 in e:\\miniconda3\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in e:\\miniconda3\\lib\\site-packages (from shap) (0.61.2)\n",
      "Requirement already satisfied: cloudpickle in e:\\miniconda3\\lib\\site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in e:\\miniconda3\\lib\\site-packages (from shap) (4.12.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in e:\\miniconda3\\lib\\site-packages (from plotly) (1.42.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in e:\\miniconda3\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\miniconda3\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in e:\\miniconda3\\lib\\site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\miniconda3\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in e:\\miniconda3\\lib\\site-packages (from matplotlib) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in e:\\miniconda3\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\miniconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: Mako in e:\\miniconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in e:\\miniconda3\\lib\\site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Collecting numpy (from optuna)\n",
      "  Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in e:\\miniconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in e:\\miniconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2025.2)\n",
      "Requirement already satisfied: greenlet>=1 in e:\\miniconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
      "Requirement already satisfied: colorama in e:\\miniconda3\\lib\\site-packages (from tqdm->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in e:\\miniconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
      "Downloading numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/12.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   - -------------------------------------- 0.5/12.6 MB 196.9 kB/s eta 0:01:02\n",
      "   -- ------------------------------------- 0.8/12.6 MB 164.7 kB/s eta 0:01:12\n",
      "   -- ------------------------------------- 0.8/12.6 MB 164.7 kB/s eta 0:01:12\n",
      "   -- ------------------------------------- 0.8/12.6 MB 164.7 kB/s eta 0:01:12\n",
      "   -- ------------------------------------- 0.8/12.6 MB 164.7 kB/s eta 0:01:12\n",
      "   -- ------------------------------------- 0.8/12.6 MB 164.7 kB/s eta 0:01:12\n",
      "   --- ------------------------------------ 1.0/12.6 MB 183.5 kB/s eta 0:01:04\n",
      "   --- ------------------------------------ 1.0/12.6 MB 183.5 kB/s eta 0:01:04\n",
      "   --- ------------------------------------ 1.0/12.6 MB 183.5 kB/s eta 0:01:04\n",
      "   --- ------------------------------------ 1.0/12.6 MB 183.5 kB/s eta 0:01:04\n",
      "   --- ------------------------------------ 1.0/12.6 MB 183.5 kB/s eta 0:01:04\n",
      "   --- ------------------------------------ 1.0/12.6 MB 183.5 kB/s eta 0:01:04\n",
      "   --- ------------------------------------ 1.0/12.6 MB 183.5 kB/s eta 0:01:04\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 183.5 kB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 183.5 kB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 183.5 kB/s eta 0:01:02\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 208.1 kB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 208.1 kB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 208.1 kB/s eta 0:00:54\n",
      "   ---- ----------------------------------- 1.6/12.6 MB 208.1 kB/s eta 0:00:54\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 221.5 kB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 221.5 kB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 221.5 kB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 221.5 kB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 221.5 kB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 221.5 kB/s eta 0:00:49\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 221.5 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------ --------------------------------- 2.1/12.6 MB 216.7 kB/s eta 0:00:49\n",
      "   ------- -------------------------------- 2.4/12.6 MB 194.4 kB/s eta 0:00:53\n",
      "   ------- -------------------------------- 2.4/12.6 MB 194.4 kB/s eta 0:00:53\n",
      "   ------- -------------------------------- 2.4/12.6 MB 194.4 kB/s eta 0:00:53\n",
      "   ------- -------------------------------- 2.4/12.6 MB 194.4 kB/s eta 0:00:53\n",
      "   ------- -------------------------------- 2.4/12.6 MB 194.4 kB/s eta 0:00:53\n",
      "   ------- -------------------------------- 2.4/12.6 MB 194.4 kB/s eta 0:00:53\n",
      "   ------- -------------------------------- 2.4/12.6 MB 194.4 kB/s eta 0:00:53\n",
      "   -------- ------------------------------- 2.6/12.6 MB 193.9 kB/s eta 0:00:52\n",
      "   -------- ------------------------------- 2.6/12.6 MB 193.9 kB/s eta 0:00:52\n",
      "   -------- ------------------------------- 2.6/12.6 MB 193.9 kB/s eta 0:00:52\n",
      "   -------- ------------------------------- 2.6/12.6 MB 193.9 kB/s eta 0:00:52\n",
      "   -------- ------------------------------- 2.6/12.6 MB 193.9 kB/s eta 0:00:52\n",
      "   -------- ------------------------------- 2.6/12.6 MB 193.9 kB/s eta 0:00:52\n",
      "   --------- ------------------------------ 2.9/12.6 MB 195.6 kB/s eta 0:00:50\n",
      "   --------- ------------------------------ 2.9/12.6 MB 195.6 kB/s eta 0:00:50\n",
      "   --------- ------------------------------ 2.9/12.6 MB 195.6 kB/s eta 0:00:50\n",
      "   --------- ------------------------------ 2.9/12.6 MB 195.6 kB/s eta 0:00:50\n",
      "   --------- ------------------------------ 2.9/12.6 MB 195.6 kB/s eta 0:00:50\n",
      "   --------- ------------------------------ 3.1/12.6 MB 197.3 kB/s eta 0:00:48\n",
      "   --------- ------------------------------ 3.1/12.6 MB 197.3 kB/s eta 0:00:48\n",
      "   --------- ------------------------------ 3.1/12.6 MB 197.3 kB/s eta 0:00:48\n",
      "   --------- ------------------------------ 3.1/12.6 MB 197.3 kB/s eta 0:00:48\n",
      "   --------- ------------------------------ 3.1/12.6 MB 197.3 kB/s eta 0:00:48\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 201.5 kB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 201.5 kB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 201.5 kB/s eta 0:00:46\n",
      "   ---------- ----------------------------- 3.4/12.6 MB 201.5 kB/s eta 0:00:46\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 208.2 kB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 208.2 kB/s eta 0:00:43\n",
      "   ----------- ---------------------------- 3.7/12.6 MB 208.2 kB/s eta 0:00:43\n",
      "   ------------ --------------------------- 3.9/12.6 MB 214.8 kB/s eta 0:00:41\n",
      "   ------------- -------------------------- 4.2/12.6 MB 227.3 kB/s eta 0:00:38\n",
      "   ------------- -------------------------- 4.2/12.6 MB 227.3 kB/s eta 0:00:38\n",
      "   -------------- ------------------------- 4.5/12.6 MB 237.7 kB/s eta 0:00:35\n",
      "   -------------- ------------------------- 4.7/12.6 MB 250.3 kB/s eta 0:00:32\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 274.8 kB/s eta 0:00:27\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 286.8 kB/s eta 0:00:25\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 286.8 kB/s eta 0:00:25\n",
      "   ------------------ --------------------- 5.8/12.6 MB 295.0 kB/s eta 0:00:24\n",
      "   ------------------- -------------------- 6.0/12.6 MB 303.8 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 6.0/12.6 MB 303.8 kB/s eta 0:00:22\n",
      "   ------------------- -------------------- 6.3/12.6 MB 313.6 kB/s eta 0:00:21\n",
      "   ------------------- -------------------- 6.3/12.6 MB 313.6 kB/s eta 0:00:21\n",
      "   -------------------- ------------------- 6.6/12.6 MB 319.1 kB/s eta 0:00:19\n",
      "   --------------------- ------------------ 6.8/12.6 MB 328.9 kB/s eta 0:00:18\n",
      "   --------------------- ------------------ 6.8/12.6 MB 328.9 kB/s eta 0:00:18\n",
      "   --------------------- ------------------ 6.8/12.6 MB 328.9 kB/s eta 0:00:18\n",
      "   --------------------- ------------------ 6.8/12.6 MB 328.9 kB/s eta 0:00:18\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 326.8 kB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 326.8 kB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 326.8 kB/s eta 0:00:17\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 326.8 kB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 326.4 kB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 326.4 kB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 326.4 kB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 326.4 kB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 326.4 kB/s eta 0:00:17\n",
      "   ----------------------- ---------------- 7.3/12.6 MB 326.4 kB/s eta 0:00:17\n",
      "   ------------------------ --------------- 7.6/12.6 MB 318.9 kB/s eta 0:00:16\n",
      "   ------------------------ --------------- 7.6/12.6 MB 318.9 kB/s eta 0:00:16\n",
      "   ------------------------ --------------- 7.6/12.6 MB 318.9 kB/s eta 0:00:16\n",
      "   ------------------------ --------------- 7.6/12.6 MB 318.9 kB/s eta 0:00:16\n",
      "   ------------------------ --------------- 7.6/12.6 MB 318.9 kB/s eta 0:00:16\n",
      "   ------------------------ --------------- 7.6/12.6 MB 318.9 kB/s eta 0:00:16\n",
      "   ------------------------ --------------- 7.9/12.6 MB 314.1 kB/s eta 0:00:16\n",
      "   ------------------------- -------------- 8.1/12.6 MB 322.3 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 8.1/12.6 MB 322.3 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 8.1/12.6 MB 322.3 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 8.1/12.6 MB 322.3 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 8.1/12.6 MB 322.3 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 8.1/12.6 MB 322.3 kB/s eta 0:00:14\n",
      "   ------------------------- -------------- 8.1/12.6 MB 322.3 kB/s eta 0:00:14\n",
      "   -------------------------- ------------- 8.4/12.6 MB 314.0 kB/s eta 0:00:14\n",
      "   -------------------------- ------------- 8.4/12.6 MB 314.0 kB/s eta 0:00:14\n",
      "   --------------------------- ------------ 8.7/12.6 MB 320.2 kB/s eta 0:00:13\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 326.2 kB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 326.2 kB/s eta 0:00:12\n",
      "   ---------------------------- ----------- 8.9/12.6 MB 326.2 kB/s eta 0:00:12\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 329.5 kB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 9.2/12.6 MB 329.5 kB/s eta 0:00:11\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 334.4 kB/s eta 0:00:10\n",
      "   ------------------------------ --------- 9.7/12.6 MB 339.6 kB/s eta 0:00:09\n",
      "   ------------------------------- -------- 10.0/12.6 MB 346.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 10.0/12.6 MB 346.1 kB/s eta 0:00:08\n",
      "   --------------------------------- ------ 10.5/12.6 MB 359.8 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 10.5/12.6 MB 359.8 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 10.5/12.6 MB 359.8 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 10.5/12.6 MB 359.8 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 359.4 kB/s eta 0:00:06\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 300.1 kB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 306.5 kB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 11.3/12.6 MB 306.5 kB/s eta 0:00:05\n",
      "   ------------------------------------ --- 11.5/12.6 MB 329.4 kB/s eta 0:00:04\n",
      "   ------------------------------------- -- 11.8/12.6 MB 335.7 kB/s eta 0:00:03\n",
      "   ---------------------------------------  12.3/12.6 MB 350.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  12.3/12.6 MB 350.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 356.7 kB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.3.2\n",
      "    Uninstalling numpy-2.3.2:\n",
      "      Successfully uninstalled numpy-2.3.2\n",
      "Successfully installed numpy-2.2.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\miniconda3\\Lib\\site-packages\\~~mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'E:\\miniconda3\\Lib\\site-packages\\~~mpy'.\n",
      "  You can safely remove it manually.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (run this first)\n",
    "%pip install optuna xgboost lightgbm catboost scikit-learn imbalanced-learn shap plotly matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11e03557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, matthews_corrcoef, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Imbalanced Learning\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier, BalancedBaggingClassifier\n",
    "\n",
    "# Gradient Boosting\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, RFECV\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Interpretation\n",
    "import shap\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa54586",
   "metadata": {},
   "source": [
    "### Step 2: Enhanced Data Preprocessing with Advanced Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e362b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training Dataset\n",
    "data = pd.read_csv('DIA_trainingset_RDKit_descriptors.csv')\n",
    "\n",
    "# extract features and target variable\n",
    "X_train = data.iloc[:, 2:]\n",
    "Y_train = data.iloc[:, 0]\n",
    "\n",
    "# Load Test Dataset\n",
    "test_data = pd.read_csv('DIA_testset_RDKit_descriptors.csv')\n",
    "X_test = test_data.iloc[:, 2:]\n",
    "Y_test = test_data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d23e85d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BalabanJ</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi0n</th>\n",
       "      <th>Chi0v</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.821</td>\n",
       "      <td>1266.407</td>\n",
       "      <td>22.121</td>\n",
       "      <td>16.781</td>\n",
       "      <td>16.781</td>\n",
       "      <td>14.901</td>\n",
       "      <td>9.203</td>\n",
       "      <td>9.203</td>\n",
       "      <td>6.668</td>\n",
       "      <td>6.668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.363</td>\n",
       "      <td>490.434</td>\n",
       "      <td>11.707</td>\n",
       "      <td>8.752</td>\n",
       "      <td>9.569</td>\n",
       "      <td>7.592</td>\n",
       "      <td>4.854</td>\n",
       "      <td>5.670</td>\n",
       "      <td>3.545</td>\n",
       "      <td>4.661</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.551</td>\n",
       "      <td>93.092</td>\n",
       "      <td>6.784</td>\n",
       "      <td>5.471</td>\n",
       "      <td>5.471</td>\n",
       "      <td>3.417</td>\n",
       "      <td>2.420</td>\n",
       "      <td>2.420</td>\n",
       "      <td>2.820</td>\n",
       "      <td>2.820</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.076</td>\n",
       "      <td>1053.003</td>\n",
       "      <td>21.836</td>\n",
       "      <td>16.995</td>\n",
       "      <td>16.995</td>\n",
       "      <td>14.274</td>\n",
       "      <td>9.926</td>\n",
       "      <td>9.926</td>\n",
       "      <td>7.662</td>\n",
       "      <td>7.662</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.888</td>\n",
       "      <td>549.823</td>\n",
       "      <td>14.629</td>\n",
       "      <td>9.746</td>\n",
       "      <td>9.746</td>\n",
       "      <td>8.752</td>\n",
       "      <td>5.040</td>\n",
       "      <td>5.040</td>\n",
       "      <td>3.601</td>\n",
       "      <td>3.601</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BalabanJ   BertzCT    Chi0   Chi0n   Chi0v    Chi1  Chi1n  Chi1v  Chi2n  \\\n",
       "0     1.821  1266.407  22.121  16.781  16.781  14.901  9.203  9.203  6.668   \n",
       "1     2.363   490.434  11.707   8.752   9.569   7.592  4.854  5.670  3.545   \n",
       "2     3.551    93.092   6.784   5.471   5.471   3.417  2.420  2.420  2.820   \n",
       "3     2.076  1053.003  21.836  16.995  16.995  14.274  9.926  9.926  7.662   \n",
       "4     2.888   549.823  14.629   9.746   9.746   8.752  5.040  5.040  3.601   \n",
       "\n",
       "   Chi2v  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  fr_term_acetylene  \\\n",
       "0  6.668  ...           0             0           0                  0   \n",
       "1  4.661  ...           0             0           0                  0   \n",
       "2  2.820  ...           0             0           0                  0   \n",
       "3  7.662  ...           0             0           0                  0   \n",
       "4  3.601  ...           0             0           0                  0   \n",
       "\n",
       "   fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  fr_unbrch_alkane  \\\n",
       "0             0            0            0             0                 0   \n",
       "1             0            0            0             1                 0   \n",
       "2             0            0            0             0                 0   \n",
       "3             0            0            0             0                 0   \n",
       "4             0            0            0             0                 0   \n",
       "\n",
       "   fr_urea  \n",
       "0        0  \n",
       "1        1  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81271971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BalabanJ</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi0n</th>\n",
       "      <th>Chi0v</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.484</td>\n",
       "      <td>743.207</td>\n",
       "      <td>21.466</td>\n",
       "      <td>18.764</td>\n",
       "      <td>18.764</td>\n",
       "      <td>14.292</td>\n",
       "      <td>12.106</td>\n",
       "      <td>12.106</td>\n",
       "      <td>10.736</td>\n",
       "      <td>10.736</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.472</td>\n",
       "      <td>868.947</td>\n",
       "      <td>21.140</td>\n",
       "      <td>16.736</td>\n",
       "      <td>17.553</td>\n",
       "      <td>14.453</td>\n",
       "      <td>10.268</td>\n",
       "      <td>11.084</td>\n",
       "      <td>7.662</td>\n",
       "      <td>8.746</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.837</td>\n",
       "      <td>1409.004</td>\n",
       "      <td>39.189</td>\n",
       "      <td>32.904</td>\n",
       "      <td>32.904</td>\n",
       "      <td>26.011</td>\n",
       "      <td>20.941</td>\n",
       "      <td>20.941</td>\n",
       "      <td>18.816</td>\n",
       "      <td>18.816</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.406</td>\n",
       "      <td>621.298</td>\n",
       "      <td>13.828</td>\n",
       "      <td>10.297</td>\n",
       "      <td>10.297</td>\n",
       "      <td>9.092</td>\n",
       "      <td>5.847</td>\n",
       "      <td>5.847</td>\n",
       "      <td>4.217</td>\n",
       "      <td>4.217</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.320</td>\n",
       "      <td>2127.996</td>\n",
       "      <td>37.955</td>\n",
       "      <td>30.849</td>\n",
       "      <td>31.666</td>\n",
       "      <td>25.910</td>\n",
       "      <td>18.066</td>\n",
       "      <td>19.115</td>\n",
       "      <td>14.930</td>\n",
       "      <td>16.060</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BalabanJ   BertzCT    Chi0   Chi0n   Chi0v    Chi1   Chi1n   Chi1v   Chi2n  \\\n",
       "0     1.484   743.207  21.466  18.764  18.764  14.292  12.106  12.106  10.736   \n",
       "1     1.472   868.947  21.140  16.736  17.553  14.453  10.268  11.084   7.662   \n",
       "2     0.837  1409.004  39.189  32.904  32.904  26.011  20.941  20.941  18.816   \n",
       "3     2.406   621.298  13.828  10.297  10.297   9.092   5.847   5.847   4.217   \n",
       "4     1.320  2127.996  37.955  30.849  31.666  25.910  18.066  19.115  14.930   \n",
       "\n",
       "    Chi2v  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  fr_term_acetylene  \\\n",
       "0  10.736  ...           0             0           0                  0   \n",
       "1   8.746  ...           0             0           0                  0   \n",
       "2  18.816  ...           0             0           0                  0   \n",
       "3   4.217  ...           0             0           0                  0   \n",
       "4  16.060  ...           1             0           0                  0   \n",
       "\n",
       "   fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  fr_unbrch_alkane  \\\n",
       "0             0            0            0             0                 0   \n",
       "1             0            0            0             0                 0   \n",
       "2             0            0            0             0                 0   \n",
       "3             0            0            0             0                 0   \n",
       "4             0            0            0             0                 0   \n",
       "\n",
       "   fr_urea  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c209b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied robust scaling\n",
      "Removed 31 highly correlated features (threshold: 0.95)\n",
      "Features reduced from 196 to 165\n",
      "Final dataset shape: Training (477, 165), Test (120, 165)\n"
     ]
    }
   ],
   "source": [
    "def advanced_preprocessing(X_train, X_test, y_train, method='robust'):\n",
    "    \"\"\"\n",
    "    Advanced preprocessing with multiple scaling options and outlier handling\n",
    "    \n",
    "    Parameters:\n",
    "    - method: 'standard', 'robust', 'minmax', 'quantile'\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, QuantileTransformer\n",
    "    \n",
    "    scalers = {\n",
    "        'standard': StandardScaler(),\n",
    "        'robust': RobustScaler(),\n",
    "        'minmax': MinMaxScaler(),\n",
    "        'quantile': QuantileTransformer(output_distribution='normal')\n",
    "    }\n",
    "    \n",
    "    scaler = scalers[method]\n",
    "    \n",
    "    # Apply scaling\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    \n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test),\n",
    "        columns=X_test.columns,\n",
    "        index=X_test.index\n",
    "    )\n",
    "    \n",
    "    print(f\"Applied {method} scaling\")\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "def remove_highly_correlated_features(X, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Remove highly correlated features using advanced correlation analysis\n",
    "    \"\"\"\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper_triangle = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    # Find features to drop\n",
    "    to_drop = [column for column in upper_triangle.columns \n",
    "               if any(upper_triangle[column] > threshold)]\n",
    "    \n",
    "    X_reduced = X.drop(columns=to_drop)\n",
    "    print(f\"Removed {len(to_drop)} highly correlated features (threshold: {threshold})\")\n",
    "    print(f\"Features reduced from {X.shape[1]} to {X_reduced.shape[1]}\")\n",
    "    \n",
    "    return X_reduced, to_drop\n",
    "\n",
    "# Apply advanced preprocessing\n",
    "X_train_enhanced, X_test_enhanced, scaler = advanced_preprocessing(\n",
    "    X_train, X_test, Y_train, method='robust'\n",
    ")\n",
    "\n",
    "# Remove highly correlated features\n",
    "X_train_final, dropped_features = remove_highly_correlated_features(\n",
    "    X_train_enhanced, threshold=0.95\n",
    ")\n",
    "X_test_final = X_test_enhanced.drop(columns=dropped_features)\n",
    "\n",
    "print(f\"Final dataset shape: Training {X_train_final.shape}, Test {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf99ac2",
   "metadata": {},
   "source": [
    "### Step 3: Advanced Feature Selection with Multiple Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "233f9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble selection chose 75 features\n",
      "Top 10 most selected features:\n",
      "EState_VSA9          3\n",
      "EState_VSA1          3\n",
      "NumAliphaticRings    3\n",
      "PEOE_VSA6            3\n",
      "EState_VSA4          3\n",
      "PEOE_VSA9            3\n",
      "SlogP_VSA10          3\n",
      "fr_urea              3\n",
      "EState_VSA10         3\n",
      "fr_piperdine         3\n",
      "Name: count, dtype: int64\n",
      "Final feature set shape: (477, 75)\n"
     ]
    }
   ],
   "source": [
    "class AdvancedFeatureSelector:\n",
    "    \"\"\"\n",
    "    Comprehensive feature selection using multiple methods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.selected_features = {}\n",
    "        \n",
    "    def mutual_information_selection(self, X, y, k='auto'):\n",
    "        \"\"\"Enhanced mutual information selection\"\"\"\n",
    "        if k == 'auto':\n",
    "            k = min(50, X.shape[1] // 2)  # Adaptive k selection\n",
    "            \n",
    "        mi_scores = mutual_info_classif(X, y, random_state=self.random_state)\n",
    "        feature_scores = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False)\n",
    "        \n",
    "        # Select top k features\n",
    "        selected_features = feature_scores.head(k).index.tolist()\n",
    "        self.selected_features['mutual_info'] = selected_features\n",
    "        \n",
    "        return selected_features, feature_scores\n",
    "    \n",
    "    def recursive_feature_elimination(self, X, y, estimator=None):\n",
    "        \"\"\"RFECV with cross-validation\"\"\"\n",
    "        if estimator is None:\n",
    "            estimator = RandomForestClassifier(n_estimators=100, random_state=self.random_state)\n",
    "            \n",
    "        rfecv = RFECV(\n",
    "            estimator=estimator,\n",
    "            step=1,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        rfecv.fit(X, y)\n",
    "        selected_features = X.columns[rfecv.support_].tolist()\n",
    "        self.selected_features['rfecv'] = selected_features\n",
    "        \n",
    "        return selected_features, rfecv\n",
    "    \n",
    "    def variance_threshold_selection(self, X, threshold=0.01):\n",
    "        \"\"\"Remove low variance features\"\"\"\n",
    "        from sklearn.feature_selection import VarianceThreshold\n",
    "        \n",
    "        selector = VarianceThreshold(threshold=threshold)\n",
    "        selector.fit(X)\n",
    "        selected_features = X.columns[selector.get_support()].tolist()\n",
    "        self.selected_features['variance'] = selected_features\n",
    "        \n",
    "        return selected_features, selector\n",
    "    \n",
    "    def statistical_selection(self, X, y, method='f_classif', k=50):\n",
    "        \"\"\"Statistical feature selection\"\"\"\n",
    "        from sklearn.feature_selection import f_classif, chi2\n",
    "        \n",
    "        if method == 'f_classif':\n",
    "            selector = SelectKBest(f_classif, k=k)\n",
    "        elif method == 'chi2':\n",
    "            # Ensure non-negative values for chi2\n",
    "            X_positive = X - X.min() + 1e-5\n",
    "            selector = SelectKBest(chi2, k=k)\n",
    "            X = X_positive\n",
    "            \n",
    "        selector.fit(X, y)\n",
    "        selected_features = X.columns[selector.get_support()].tolist()\n",
    "        self.selected_features['statistical'] = selected_features\n",
    "        \n",
    "        return selected_features, selector\n",
    "    \n",
    "    def ensemble_selection(self, X, y, methods=['mutual_info', 'rfecv', 'statistical']):\n",
    "        \"\"\"Combine multiple selection methods\"\"\"\n",
    "        all_selected = []\n",
    "        \n",
    "        if 'mutual_info' in methods:\n",
    "            features, _ = self.mutual_information_selection(X, y)\n",
    "            all_selected.extend(features)\n",
    "            \n",
    "        if 'rfecv' in methods:\n",
    "            features, _ = self.recursive_feature_elimination(X, y)\n",
    "            all_selected.extend(features)\n",
    "            \n",
    "        if 'statistical' in methods:\n",
    "            features, _ = self.statistical_selection(X, y)\n",
    "            all_selected.extend(features)\n",
    "            \n",
    "        # Count feature frequency\n",
    "        feature_counts = pd.Series(all_selected).value_counts()\n",
    "        \n",
    "        # Select features that appear in at least 2 methods\n",
    "        ensemble_features = feature_counts[feature_counts >= 2].index.tolist()\n",
    "        self.selected_features['ensemble'] = ensemble_features\n",
    "        \n",
    "        return ensemble_features, feature_counts\n",
    "\n",
    "# Apply advanced feature selection\n",
    "feature_selector = AdvancedFeatureSelector(random_state=42)\n",
    "\n",
    "# Run ensemble selection\n",
    "ensemble_features, feature_counts = feature_selector.ensemble_selection(\n",
    "    X_train_final, Y_train, methods=['mutual_info', 'rfecv', 'statistical']\n",
    ")\n",
    "\n",
    "print(f\"Ensemble selection chose {len(ensemble_features)} features\")\n",
    "print(f\"Top 10 most selected features:\")\n",
    "print(feature_counts.head(10))\n",
    "\n",
    "# Create final feature set\n",
    "X_train_selected = X_train_final[ensemble_features]\n",
    "X_test_selected = X_test_final[ensemble_features]\n",
    "\n",
    "print(f\"Final feature set shape: {X_train_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a720e",
   "metadata": {},
   "source": [
    "### Step 4: Advanced Model Development with Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2a1e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptunaModelOptimizer:\n",
    "    \"\"\"\n",
    "    Advanced hyperparameter optimization using Optuna\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_trials=100, cv_folds=5, random_state=42):\n",
    "        self.n_trials = n_trials\n",
    "        self.cv_folds = cv_folds\n",
    "        self.random_state = random_state\n",
    "        self.best_params = {}\n",
    "        self.study_results = {}\n",
    "    \n",
    "    def objective_function(self, trial, model_type, X, y):\n",
    "        \"\"\"Unified objective function for all models\"\"\"\n",
    "        \n",
    "        if model_type == 'random_forest':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.5, 0.7]),\n",
    "                'random_state': self.random_state,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            model = RandomForestClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'xgboost':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "                'random_state': self.random_state,\n",
    "                'eval_metric': 'logloss',\n",
    "                'verbosity': 0\n",
    "            }\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'lightgbm':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "                'random_state': self.random_state,\n",
    "                'verbosity': -1,\n",
    "                'force_col_wise': True\n",
    "            }\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'catboost':\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'depth': trial.suggest_int('depth', 3, 10),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "                'random_state': self.random_state,\n",
    "                'verbose': False\n",
    "            }\n",
    "            model = cb.CatBoostClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'balanced_rf':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.5, 0.7]),\n",
    "                'random_state': self.random_state,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            model = BalancedRandomForestClassifier(**params)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        scores = cross_validate(\n",
    "            model, X, y, \n",
    "            cv=cv, \n",
    "            scoring=['roc_auc', 'accuracy', 'f1'],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Return weighted score (prioritize AUC and F1)\n",
    "        return 0.5 * scores['test_roc_auc'].mean() + 0.3 * scores['test_f1'].mean() + 0.2 * scores['test_accuracy'].mean()\n",
    "    \n",
    "    def optimize_model(self, model_type, X, y):\n",
    "        \"\"\"Optimize a specific model type\"\"\"\n",
    "        print(f\"Optimizing {model_type}...\")\n",
    "        \n",
    "        study = optuna.create_study(\n",
    "            direction='maximize',\n",
    "            sampler=TPESampler(seed=self.random_state)\n",
    "        )\n",
    "        \n",
    "        study.optimize(\n",
    "            lambda trial: self.objective_function(trial, model_type, X, y),\n",
    "            n_trials=self.n_trials,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        self.best_params[model_type] = study.best_params\n",
    "        self.study_results[model_type] = study\n",
    "        \n",
    "        print(f\"Best {model_type} score: {study.best_value:.4f}\")\n",
    "        print(f\"Best {model_type} params: {study.best_params}\")\n",
    "        \n",
    "        return study.best_params, study.best_value\n",
    "    \n",
    "    def optimize_all_models(self, X, y, models=['balanced_rf', 'xgboost', 'lightgbm', 'catboost']):\n",
    "        \"\"\"Optimize all specified models\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for model_type in models:\n",
    "            params, score = self.optimize_model(model_type, X, y)\n",
    "            results[model_type] = {'params': params, 'score': score}\n",
    "            \n",
    "        return results\n",
    "\n",
    "    # Add this method to your OptunaModelOptimizer class\n",
    "    def create_optimized_models(self, optimization_results):\n",
    "        \"\"\"Create models with optimized parameters\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        for model_type, result in optimization_results.items():\n",
    "            params = result['params']\n",
    "            params['random_state'] = self.random_state\n",
    "            \n",
    "            if model_type == 'balanced_rf':\n",
    "                params['n_jobs'] = -1\n",
    "                models[model_type] = BalancedRandomForestClassifier(**params)\n",
    "            elif model_type == 'xgboost':\n",
    "                params['eval_metric'] = 'logloss'\n",
    "                params['verbosity'] = 0\n",
    "                models[model_type] = xgb.XGBClassifier(**params)\n",
    "            elif model_type == 'lightgbm':\n",
    "                params['verbosity'] = -1\n",
    "                params['force_col_wise'] = True\n",
    "                models[model_type] = lgb.LGBMClassifier(**params)\n",
    "            elif model_type == 'catboost':\n",
    "                params['verbose'] = False\n",
    "                models[model_type] = cb.CatBoostClassifier(**params)\n",
    "                \n",
    "        return models\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = OptunaModelOptimizer(n_trials=50, cv_folds=5)  # Reduce trials for demo\n",
    "\n",
    "# Optimize models (this will take some time)\n",
    "optimization_results = optimizer.optimize_all_models(\n",
    "    X_train_selected, Y_train, \n",
    "    models=['balanced_rf', 'xgboost', 'lightgbm']  # Start with these three\n",
    ")\n",
    "\n",
    "print(\"\\nOptimization completed!\")\n",
    "for model, result in optimization_results.items():\n",
    "    print(f\"{model}: Score = {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba91cb",
   "metadata": {},
   "source": [
    "### Step 5: Advanced Model Ensemble and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb5ac844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating meta-features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"e:\\miniconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"e:\\miniconda3\\Lib\\subprocess.py\", line 556, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\miniconda3\\Lib\\subprocess.py\", line 1038, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"e:\\miniconda3\\Lib\\subprocess.py\", line 1550, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training meta-model...\n",
      "Training base models on full data...\n",
      "Ensemble training completed!\n"
     ]
    }
   ],
   "source": [
    "class AdvancedEnsemble:\n",
    "    \"\"\"\n",
    "    Advanced ensemble methods including stacking and blending\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_models, meta_model=None, cv_folds=5, random_state=42):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model or lgb.LGBMClassifier(random_state=random_state, verbosity=-1)\n",
    "        self.cv_folds = cv_folds\n",
    "        self.random_state = random_state\n",
    "        self.trained_models = {}\n",
    "        \n",
    "    def create_optimized_models(self, optimization_results):\n",
    "        \"\"\"Create models with optimized parameters\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        for model_type, result in optimization_results.items():\n",
    "            params = result['params']\n",
    "            params['random_state'] = self.random_state\n",
    "            \n",
    "            if model_type == 'balanced_rf':\n",
    "                params['n_jobs'] = -1\n",
    "                models[model_type] = BalancedRandomForestClassifier(**params)\n",
    "            elif model_type == 'xgboost':\n",
    "                params['eval_metric'] = 'logloss'\n",
    "                params['verbosity'] = 0\n",
    "                models[model_type] = xgb.XGBClassifier(**params)\n",
    "            elif model_type == 'lightgbm':\n",
    "                params['verbosity'] = -1\n",
    "                params['force_col_wise'] = True\n",
    "                models[model_type] = lgb.LGBMClassifier(**params)\n",
    "            elif model_type == 'catboost':\n",
    "                params['verbose'] = False\n",
    "                models[model_type] = cb.CatBoostClassifier(**params)\n",
    "                \n",
    "        return models\n",
    "    \n",
    "    def stacking_cv(self, X, y):\n",
    "        \"\"\"Generate meta-features using cross-validation\"\"\"\n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "            X_train_fold = X.iloc[train_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            X_val_fold = X.iloc[val_idx]\n",
    "            \n",
    "            for i, (name, model) in enumerate(self.base_models.items()):\n",
    "                # Clone and train model\n",
    "                model_clone = clone(model)\n",
    "                model_clone.fit(X_train_fold, y_train_fold)\n",
    "                \n",
    "                # Predict on validation set\n",
    "                pred_proba = model_clone.predict_proba(X_val_fold)[:, 1]\n",
    "                meta_features[val_idx, i] = pred_proba\n",
    "                \n",
    "        return meta_features\n",
    "    \n",
    "    def fit_stacking(self, X, y):\n",
    "        \"\"\"Fit stacking ensemble\"\"\"\n",
    "        print(\"Generating meta-features...\")\n",
    "        meta_features = self.stacking_cv(X, y)\n",
    "        \n",
    "        print(\"Training meta-model...\")\n",
    "        self.meta_model.fit(meta_features, y)\n",
    "        \n",
    "        # Train base models on full data\n",
    "        print(\"Training base models on full data...\")\n",
    "        for name, model in self.base_models.items():\n",
    "            model.fit(X, y)\n",
    "            self.trained_models[name] = model\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_stacking(self, X):\n",
    "        \"\"\"Predict using stacking ensemble\"\"\"\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.trained_models.items()):\n",
    "            pred_proba = model.predict_proba(X)[:, 1]\n",
    "            meta_features[:, i] = pred_proba\n",
    "            \n",
    "        return self.meta_model.predict(meta_features)\n",
    "    \n",
    "    def predict_proba_stacking(self, X):\n",
    "        \"\"\"Predict probabilities using stacking ensemble\"\"\"\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.trained_models.items()):\n",
    "            pred_proba = model.predict_proba(X)[:, 1]\n",
    "            meta_features[:, i] = pred_proba\n",
    "            \n",
    "        return self.meta_model.predict_proba(meta_features)\n",
    "    \n",
    "    def weighted_average_ensemble(self, X, weights=None):\n",
    "        \"\"\"Simple weighted average ensemble\"\"\"\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(self.trained_models)) / len(self.trained_models)\n",
    "            \n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.trained_models.items()):\n",
    "            pred_proba = model.predict_proba(X)[:, 1]\n",
    "            predictions += weights[i] * pred_proba\n",
    "            \n",
    "        return (predictions > 0.5).astype(int), predictions\n",
    "\n",
    "# Create optimized models\n",
    "optimized_models = optimizer.create_optimized_models(optimization_results)\n",
    "\n",
    "# Create ensemble\n",
    "ensemble = AdvancedEnsemble(optimized_models)\n",
    "\n",
    "# Fit stacking ensemble\n",
    "ensemble.fit_stacking(X_train_selected, Y_train)\n",
    "\n",
    "print(\"Ensemble training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b44c5",
   "metadata": {},
   "source": [
    "### Step 6: Comprehensive Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f42ddbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating balanced_rf...\n",
      "Evaluating xgboost...\n",
      "Evaluating lightgbm...\n",
      "\n",
      "Model Comparison Results:\n",
      "               Model  CV_accuracy_mean  CV_accuracy_std  CV_precision_mean  \\\n",
      "0        balanced_rf            0.8240           0.0423             0.6624   \n",
      "1            xgboost            0.8281           0.0136             0.7660   \n",
      "2           lightgbm            0.8239           0.0214             0.7190   \n",
      "3  Stacking_Ensemble               NaN              NaN                NaN   \n",
      "\n",
      "   CV_precision_std  CV_recall_mean  CV_recall_std  CV_f1_mean  CV_f1_std  \\\n",
      "0            0.0993          0.6362         0.0832      0.6434     0.0680   \n",
      "1            0.0362          0.4413         0.0667      0.5567     0.0552   \n",
      "2            0.0559          0.4750         0.0519      0.5712     0.0511   \n",
      "3               NaN             NaN            NaN         NaN        NaN   \n",
      "\n",
      "   CV_auc_mean  ...  CV_specificity_mean  CV_specificity_std  Test_accuracy  \\\n",
      "0       0.8507  ...               0.8857              0.0553         0.8167   \n",
      "1       0.8430  ...               0.9555              0.0103         0.8000   \n",
      "2       0.8410  ...               0.9387              0.0145         0.8083   \n",
      "3          NaN  ...                  NaN                 NaN         0.8250   \n",
      "\n",
      "   Test_precision  Test_recall  Test_f1  Test_mcc  Test_auc  Test_sensitivity  \\\n",
      "0          0.6538       0.5667   0.6071    0.4905    0.8863            0.5667   \n",
      "1          0.7500       0.3000   0.4286    0.3849    0.8881            0.3000   \n",
      "2          0.7692       0.3333   0.4651    0.4180    0.8748            0.3333   \n",
      "3          0.7368       0.4667   0.5714    0.4876    0.8607            0.4667   \n",
      "\n",
      "   Test_specificity  \n",
      "0            0.9000  \n",
      "1            0.9667  \n",
      "2            0.9667  \n",
      "3            0.9444  \n",
      "\n",
      "[4 rows x 25 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "width": 3
         },
         "mode": "lines",
         "name": "balanced_rf (AUC = 0.886)",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAF2zBFmzBhj8XbMEWbMGGPxEREREREaE/ERERERERoT8XbMEWbMGmPxdswRZswaY/HMdxHMdxrD8cx3Ecx3GsPxzHcRzHcbw/HMdxHMdxvD8RERERERHBPxEREREREcE/VVVVVVVVxT9VVVVVVVXFP1uwBVuwBcs/W7AFW7AFyz8cx3Ecx3HMPxzHcRzHccw/3t3d3d3dzT/e3d3d3d3NP7AFW7AFW9A/sAVbsAVb0D/SJ33SJ33SP9InfdInfdI/9Umf9Emf1D/1SZ/0SZ/UP7y7u7u7u9s/vLu7u7u72z8AAAAAAADwPw==",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAAARERERERGhP5qZmZmZmbk/mpmZmZmZuT8RERERERHRPxEREREREdE/d3d3d3d31z93d3d3d3fXPwAAAAAAAOA/AAAAAAAA4D8iIiIiIiLiPyIiIiIiIuI/MzMzMzMz4z8zMzMzMzPjP0REREREROQ/RERERERE5D93d3d3d3fnP3d3d3d3d+c/iYiIiIiI6D+JiIiIiIjoP5qZmZmZmek/mpmZmZmZ6T+rqqqqqqrqP6uqqqqqquo/zczMzMzM7D/NzMzMzMzsP97d3d3d3e0/3t3d3d3d7T/v7u7u7u7uP+/u7u7u7u4/AAAAAAAA8D8AAAAAAADwPw==",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "width": 3
         },
         "mode": "lines",
         "name": "xgboost (AUC = 0.888)",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAF2zBFmzBhj8XbMEWbMGGPxdswRZswZY/F2zBFmzBlj8RERERERGhPxEREREREaE/F2zBFmzBpj8XbMEWbMGmPxzHcRzHcaw/HMdxHMdxrD8cx3Ecx3GsP5Q+6ZM+6cM/lD7pkz7pwz9VVVVVVVXFP1VVVVVVVcU/2IIt2IItyD/Ygi3Ygi3IP5qZmZmZmck/mpmZmZmZyT+f9Emf9EnPP5/0SZ/0Sc8/sAVbsAVb0D+wBVuwBVvQP9InfdInfdI/0id90id90j8zMzMzMzPTPzMzMzMzM9M/F2zBFmzB1j8XbMEWbMHWPwAAAAAAAPA/",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAAARERERERGhP1VVVVVVVcU/VVVVVVVVxT+amZmZmZnJP5qZmZmZmck/ERERERER0T8RERERERHRP97d3d3d3d0/3t3d3d3d3T8AAAAAAADgPwAAAAAAAOA/IiIiIiIi4j8zMzMzMzPjPzMzMzMzM+M/RERERERE5D9ERERERETkP1VVVVVVVeU/VVVVVVVV5T9mZmZmZmbmP2ZmZmZmZuY/d3d3d3d35z93d3d3d3fnP7y7u7u7u+s/vLu7u7u76z/NzMzMzMzsP83MzMzMzOw/3t3d3d3d7T/e3d3d3d3tP+/u7u7u7u4/7+7u7u7u7j8AAAAAAADwPwAAAAAAAPA/",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "width": 3
         },
         "mode": "lines",
         "name": "lightgbm (AUC = 0.875)",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAF2zBFmzBhj8XbMEWbMGGPxdswRZswZY/F2zBFmzBlj8RERERERGhPxEREREREaE/F2zBFmzBpj8XbMEWbMGmP5Q+6ZM+6bM/lD7pkz7psz+amZmZmZm5P5qZmZmZmbk/HMdxHMdxvD8cx3Ecx3G8PxEREREREcE/ERERERERwT/SJ33SJ33CP9InfdInfcI/W7AFW7AFyz9bsAVbsAXLP1uwBVuwBcs/HMdxHMdxzD8cx3Ecx3HMP97d3d3d3c0/3t3d3d3dzT+f9Emf9EnPP5/0SZ/0Sc8/3t3d3d3d3T/e3d3d3d3dPwAAAAAAAPA/",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAAARERERERGhP1VVVVVVVcU/VVVVVVVVxT+amZmZmZnJP5qZmZmZmck/3t3d3d3dzT/e3d3d3d3NP1VVVVVVVdU/VVVVVVVV1T+8u7u7u7vbP7y7u7u7u9s/AAAAAAAA4D8AAAAAAADgPxEREREREeE/ERERERER4T8zMzMzMzPjPzMzMzMzM+M/RERERERE5D9ERERERETkP1VVVVVVVeU/VVVVVVVV5T93d3d3d3fnP4mIiIiIiOg/iYiIiIiI6D+amZmZmZnpP5qZmZmZmek/zczMzMzM7D/NzMzMzMzsP97d3d3d3e0/3t3d3d3d7T8AAAAAAADwPwAAAAAAAPA/",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "width": 3
         },
         "mode": "lines",
         "name": "Stacking_Ensemble (AUC = 0.861)",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAABdswRZswYY/F2zBFmzBhj8XbMEWbMGGPxEREREREaE/ERERERERoT8cx3Ecx3GsPxzHcRzHcaw/mpmZmZmZuT+amZmZmZm5P9InfdInfcI/0id90id9wj/SJ33SJ33CP9iCLdiCLcg/2IIt2IItyD+f9Emf9EnPP5/0SZ/0Sc8/ERERERER0T8RERERERHRP3Icx3Ecx9E/chzHcRzH0T8zMzMzMzPTPzMzMzMzM9M/lD7pkz7p0z+UPumTPunTP7y7u7u7u9s/vLu7u7u72z8AAAAAAADgPwAAAAAAAOA/YQu2YAu24D9yHMdxHMfhPwAAAAAAAPA/",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAAARERERERGhPxEREREREaE/VVVVVVVVxT/e3d3d3d3NP97d3d3d3c0/VVVVVVVV1T9VVVVVVVXVP97d3d3d3d0/3t3d3d3d3T8RERERERHhPxEREREREeE/MzMzMzMz4z9VVVVVVVXlP1VVVVVVVeU/ZmZmZmZm5j9mZmZmZmbmP5qZmZmZmek/mpmZmZmZ6T+rqqqqqqrqP6uqqqqqquo/vLu7u7u76z+8u7u7u7vrP83MzMzMzOw/zczMzMzM7D/e3d3d3d3tP97d3d3d3e0/7+7u7u7u7j/v7u7u7u7uPwAAAAAAAPA/AAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "color": "gray",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "Random (AUC = 0.5)",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ]
        }
       ],
       "layout": {
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ROC Curves Comparison"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "title": {
          "text": "True Positive Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ComprehensiveEvaluator:\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with multiple metrics and visualizations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        \n",
    "    def calculate_metrics(self, y_true, y_pred, y_pred_proba=None):\n",
    "        \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "        from sklearn.metrics import (\n",
    "            accuracy_score, precision_score, recall_score, f1_score,\n",
    "            roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
    "            classification_report\n",
    "        )\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred),\n",
    "            'recall': recall_score(y_true, y_pred),\n",
    "            'f1': f1_score(y_true, y_pred),\n",
    "            'mcc': matthews_corrcoef(y_true, y_pred)\n",
    "        }\n",
    "        \n",
    "        if y_pred_proba is not None:\n",
    "            metrics['auc'] = roc_auc_score(y_true, y_pred_proba)\n",
    "            \n",
    "        # Confusion matrix components\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        metrics.update({\n",
    "            'sensitivity': tp / (tp + fn),\n",
    "            'specificity': tn / (tn + fp),\n",
    "            'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn\n",
    "        })\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def cross_validation_evaluation(self, model, X, y, cv_folds=5):\n",
    "        \"\"\"Comprehensive cross-validation evaluation\"\"\"\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        cv_results = {\n",
    "            'accuracy': [], 'precision': [], 'recall': [], 'f1': [],\n",
    "            'auc': [], 'mcc': [], 'sensitivity': [], 'specificity': []\n",
    "        }\n",
    "        \n",
    "        for train_idx, val_idx in cv.split(X, y):\n",
    "            X_train_fold = X.iloc[train_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            X_val_fold = X.iloc[val_idx]\n",
    "            y_val_fold = y.iloc[val_idx]\n",
    "            \n",
    "            # Train and predict\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = model_clone.predict(X_val_fold)\n",
    "            y_pred_proba = model_clone.predict_proba(X_val_fold)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            fold_metrics = self.calculate_metrics(y_val_fold, y_pred, y_pred_proba)\n",
    "            \n",
    "            for metric in cv_results:\n",
    "                if metric in fold_metrics:\n",
    "                    cv_results[metric].append(fold_metrics[metric])\n",
    "        \n",
    "        # Calculate means and stds\n",
    "        cv_summary = {}\n",
    "        for metric, values in cv_results.items():\n",
    "            cv_summary[f'{metric}_mean'] = np.mean(values)\n",
    "            cv_summary[f'{metric}_std'] = np.std(values)\n",
    "            \n",
    "        return cv_summary\n",
    "    \n",
    "    def evaluate_model(self, model, X_train, y_train, X_test, y_test, model_name):\n",
    "        \"\"\"Complete model evaluation\"\"\"\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        # Cross-validation results\n",
    "        cv_results = self.cross_validation_evaluation(model, X_train, y_train)\n",
    "        \n",
    "        # Train on full training set and test\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_pred_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Test set metrics\n",
    "        test_metrics = self.calculate_metrics(y_test, y_pred_test, y_pred_proba_test)\n",
    "        \n",
    "        # Store results\n",
    "        self.results[model_name] = {\n",
    "            'cv_results': cv_results,\n",
    "            'test_metrics': test_metrics,\n",
    "            'predictions': {\n",
    "                'y_pred': y_pred_test,\n",
    "                'y_pred_proba': y_pred_proba_test\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return cv_results, test_metrics\n",
    "    \n",
    "    def create_results_dataframe(self):\n",
    "        \"\"\"Create comprehensive results DataFrame\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        for model_name, result in self.results.items():\n",
    "            row = {'Model': model_name}\n",
    "            \n",
    "            # Add CV results (only if they exist)\n",
    "            if 'cv_results' in result:\n",
    "                for metric, value in result['cv_results'].items():\n",
    "                    row[f'CV_{metric}'] = value\n",
    "            else:\n",
    "                # Fill with NaN for missing CV results\n",
    "                cv_metrics = ['accuracy_mean', 'accuracy_std', 'precision_mean', 'precision_std', \n",
    "                            'recall_mean', 'recall_std', 'f1_mean', 'f1_std', 'auc_mean', 'auc_std',\n",
    "                            'mcc_mean', 'mcc_std', 'sensitivity_mean', 'sensitivity_std', \n",
    "                            'specificity_mean', 'specificity_std']\n",
    "                for metric in cv_metrics:\n",
    "                    row[f'CV_{metric}'] = np.nan\n",
    "                \n",
    "            # Add test results\n",
    "            for metric, value in result['test_metrics'].items():\n",
    "                if metric not in ['tp', 'tn', 'fp', 'fn']:\n",
    "                    row[f'Test_{metric}'] = value\n",
    "                    \n",
    "            data.append(row)\n",
    "            \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def plot_roc_curves(self, X_test, y_test):\n",
    "        \"\"\"Plot ROC curves for all models\"\"\"\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        for model_name, results in self.results.items():\n",
    "            y_pred_proba = results['predictions']['y_pred_proba']\n",
    "            \n",
    "            from sklearn.metrics import roc_curve\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            auc_score = results['test_metrics']['auc']\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=fpr, y=tpr,\n",
    "                mode='lines',\n",
    "                name=f'{model_name} (AUC = {auc_score:.3f})',\n",
    "                line=dict(width=3)\n",
    "            ))\n",
    "        \n",
    "        # Add diagonal line\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[0, 1], y=[0, 1],\n",
    "            mode='lines',\n",
    "            name='Random (AUC = 0.5)',\n",
    "            line=dict(dash='dash', color='gray')\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='ROC Curves Comparison',\n",
    "            xaxis_title='False Positive Rate',\n",
    "            yaxis_title='True Positive Rate',\n",
    "            width=800, height=600\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "    def plot_feature_importance(self, model, feature_names, model_name, top_n=20):\n",
    "        \"\"\"Plot feature importance\"\"\"\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            importances = np.abs(model.coef_[0])\n",
    "        else:\n",
    "            print(f\"Cannot extract feature importance for {model_name}\")\n",
    "            return\n",
    "            \n",
    "        feature_imp = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        top_features = feature_imp.head(top_n)\n",
    "        \n",
    "        fig = px.bar(\n",
    "            top_features.iloc[::-1],  # Reverse for better visualization\n",
    "            x='importance',\n",
    "            y='feature',\n",
    "            orientation='h',\n",
    "            title=f'Top {top_n} Feature Importances - {model_name}'\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=600)\n",
    "        fig.show()\n",
    "\n",
    "# Evaluate individual models\n",
    "evaluator = ComprehensiveEvaluator()\n",
    "\n",
    "# Evaluate optimized models\n",
    "for model_name, model in optimized_models.items():\n",
    "    evaluator.evaluate_model(\n",
    "        model, X_train_selected, Y_train, X_test_selected, Y_test, model_name\n",
    "    )\n",
    "\n",
    "# Evaluate ensemble\n",
    "ensemble_pred = ensemble.predict_stacking(X_test_selected)\n",
    "ensemble_pred_proba = ensemble.predict_proba_stacking(X_test_selected)[:, 1]\n",
    "\n",
    "# Add ensemble results manually\n",
    "ensemble_test_metrics = evaluator.calculate_metrics(Y_test, ensemble_pred, ensemble_pred_proba)\n",
    "\n",
    "# # cross-validate ensemble\n",
    "# cv_results = evaluator.cross_validation_evaluation(ensemble, X_train_selected, Y_train)\n",
    "\n",
    "evaluator.results['Stacking_Ensemble'] = {\n",
    "    # 'cv_results': cv_results,\n",
    "    'test_metrics': ensemble_test_metrics,\n",
    "    'predictions': {\n",
    "        'y_pred': ensemble_pred,\n",
    "        'y_pred_proba': ensemble_pred_proba\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create results summary\n",
    "results_df = evaluator.create_results_dataframe()\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Plot ROC curves\n",
    "evaluator.plot_roc_curves(X_test_selected, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e0705",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
