{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3912a3f",
   "metadata": {},
   "source": [
    "# XGBoost, LightBGM, CatBoost (normal + advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c210612",
   "metadata": {},
   "source": [
    "### 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ae7f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: 4.2.0 not found\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries (run this first)\n",
    "%pip install optuna xgboost lightgbm catboost scikit-learn imbalanced-learn shap plotly matplotlib seaborn nbformat>=4.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "11e03557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import all necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, matthews_corrcoef, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import clone\n",
    "\n",
    "# Imbalanced Learning\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier, BalancedBaggingClassifier\n",
    "\n",
    "# Gradient Boosting\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as cb\n",
    "\n",
    "# Hyperparameter Optimization\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, RFECV\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Interpretation\n",
    "import shap\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa54586",
   "metadata": {},
   "source": [
    "### Step 2: Enhanced Data Preprocessing with Advanced Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1e362b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Training Dataset\n",
    "data = pd.read_csv('DIA_trainingset_RDKit_descriptors.csv')\n",
    "\n",
    "# extract features and target variable\n",
    "X_train = data.iloc[:, 2:]\n",
    "Y_train = data.iloc[:, 0]\n",
    "\n",
    "# Load Test Dataset\n",
    "test_data = pd.read_csv('DIA_testset_RDKit_descriptors.csv')\n",
    "X_test = test_data.iloc[:, 2:]\n",
    "Y_test = test_data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d23e85d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BalabanJ</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi0n</th>\n",
       "      <th>Chi0v</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.821</td>\n",
       "      <td>1266.407</td>\n",
       "      <td>22.121</td>\n",
       "      <td>16.781</td>\n",
       "      <td>16.781</td>\n",
       "      <td>14.901</td>\n",
       "      <td>9.203</td>\n",
       "      <td>9.203</td>\n",
       "      <td>6.668</td>\n",
       "      <td>6.668</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.363</td>\n",
       "      <td>490.434</td>\n",
       "      <td>11.707</td>\n",
       "      <td>8.752</td>\n",
       "      <td>9.569</td>\n",
       "      <td>7.592</td>\n",
       "      <td>4.854</td>\n",
       "      <td>5.670</td>\n",
       "      <td>3.545</td>\n",
       "      <td>4.661</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.551</td>\n",
       "      <td>93.092</td>\n",
       "      <td>6.784</td>\n",
       "      <td>5.471</td>\n",
       "      <td>5.471</td>\n",
       "      <td>3.417</td>\n",
       "      <td>2.420</td>\n",
       "      <td>2.420</td>\n",
       "      <td>2.820</td>\n",
       "      <td>2.820</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.076</td>\n",
       "      <td>1053.003</td>\n",
       "      <td>21.836</td>\n",
       "      <td>16.995</td>\n",
       "      <td>16.995</td>\n",
       "      <td>14.274</td>\n",
       "      <td>9.926</td>\n",
       "      <td>9.926</td>\n",
       "      <td>7.662</td>\n",
       "      <td>7.662</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.888</td>\n",
       "      <td>549.823</td>\n",
       "      <td>14.629</td>\n",
       "      <td>9.746</td>\n",
       "      <td>9.746</td>\n",
       "      <td>8.752</td>\n",
       "      <td>5.040</td>\n",
       "      <td>5.040</td>\n",
       "      <td>3.601</td>\n",
       "      <td>3.601</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BalabanJ   BertzCT    Chi0   Chi0n   Chi0v    Chi1  Chi1n  Chi1v  Chi2n  \\\n",
       "0     1.821  1266.407  22.121  16.781  16.781  14.901  9.203  9.203  6.668   \n",
       "1     2.363   490.434  11.707   8.752   9.569   7.592  4.854  5.670  3.545   \n",
       "2     3.551    93.092   6.784   5.471   5.471   3.417  2.420  2.420  2.820   \n",
       "3     2.076  1053.003  21.836  16.995  16.995  14.274  9.926  9.926  7.662   \n",
       "4     2.888   549.823  14.629   9.746   9.746   8.752  5.040  5.040  3.601   \n",
       "\n",
       "   Chi2v  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  fr_term_acetylene  \\\n",
       "0  6.668  ...           0             0           0                  0   \n",
       "1  4.661  ...           0             0           0                  0   \n",
       "2  2.820  ...           0             0           0                  0   \n",
       "3  7.662  ...           0             0           0                  0   \n",
       "4  3.601  ...           0             0           0                  0   \n",
       "\n",
       "   fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  fr_unbrch_alkane  \\\n",
       "0             0            0            0             0                 0   \n",
       "1             0            0            0             1                 0   \n",
       "2             0            0            0             0                 0   \n",
       "3             0            0            0             0                 0   \n",
       "4             0            0            0             0                 0   \n",
       "\n",
       "   fr_urea  \n",
       "0        0  \n",
       "1        1  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "81271971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BalabanJ</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>Chi0</th>\n",
       "      <th>Chi0n</th>\n",
       "      <th>Chi0v</th>\n",
       "      <th>Chi1</th>\n",
       "      <th>Chi1n</th>\n",
       "      <th>Chi1v</th>\n",
       "      <th>Chi2n</th>\n",
       "      <th>Chi2v</th>\n",
       "      <th>...</th>\n",
       "      <th>fr_sulfide</th>\n",
       "      <th>fr_sulfonamd</th>\n",
       "      <th>fr_sulfone</th>\n",
       "      <th>fr_term_acetylene</th>\n",
       "      <th>fr_tetrazole</th>\n",
       "      <th>fr_thiazole</th>\n",
       "      <th>fr_thiocyan</th>\n",
       "      <th>fr_thiophene</th>\n",
       "      <th>fr_unbrch_alkane</th>\n",
       "      <th>fr_urea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.484</td>\n",
       "      <td>743.207</td>\n",
       "      <td>21.466</td>\n",
       "      <td>18.764</td>\n",
       "      <td>18.764</td>\n",
       "      <td>14.292</td>\n",
       "      <td>12.106</td>\n",
       "      <td>12.106</td>\n",
       "      <td>10.736</td>\n",
       "      <td>10.736</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.472</td>\n",
       "      <td>868.947</td>\n",
       "      <td>21.140</td>\n",
       "      <td>16.736</td>\n",
       "      <td>17.553</td>\n",
       "      <td>14.453</td>\n",
       "      <td>10.268</td>\n",
       "      <td>11.084</td>\n",
       "      <td>7.662</td>\n",
       "      <td>8.746</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.837</td>\n",
       "      <td>1409.004</td>\n",
       "      <td>39.189</td>\n",
       "      <td>32.904</td>\n",
       "      <td>32.904</td>\n",
       "      <td>26.011</td>\n",
       "      <td>20.941</td>\n",
       "      <td>20.941</td>\n",
       "      <td>18.816</td>\n",
       "      <td>18.816</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.406</td>\n",
       "      <td>621.298</td>\n",
       "      <td>13.828</td>\n",
       "      <td>10.297</td>\n",
       "      <td>10.297</td>\n",
       "      <td>9.092</td>\n",
       "      <td>5.847</td>\n",
       "      <td>5.847</td>\n",
       "      <td>4.217</td>\n",
       "      <td>4.217</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.320</td>\n",
       "      <td>2127.996</td>\n",
       "      <td>37.955</td>\n",
       "      <td>30.849</td>\n",
       "      <td>31.666</td>\n",
       "      <td>25.910</td>\n",
       "      <td>18.066</td>\n",
       "      <td>19.115</td>\n",
       "      <td>14.930</td>\n",
       "      <td>16.060</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BalabanJ   BertzCT    Chi0   Chi0n   Chi0v    Chi1   Chi1n   Chi1v   Chi2n  \\\n",
       "0     1.484   743.207  21.466  18.764  18.764  14.292  12.106  12.106  10.736   \n",
       "1     1.472   868.947  21.140  16.736  17.553  14.453  10.268  11.084   7.662   \n",
       "2     0.837  1409.004  39.189  32.904  32.904  26.011  20.941  20.941  18.816   \n",
       "3     2.406   621.298  13.828  10.297  10.297   9.092   5.847   5.847   4.217   \n",
       "4     1.320  2127.996  37.955  30.849  31.666  25.910  18.066  19.115  14.930   \n",
       "\n",
       "    Chi2v  ...  fr_sulfide  fr_sulfonamd  fr_sulfone  fr_term_acetylene  \\\n",
       "0  10.736  ...           0             0           0                  0   \n",
       "1   8.746  ...           0             0           0                  0   \n",
       "2  18.816  ...           0             0           0                  0   \n",
       "3   4.217  ...           0             0           0                  0   \n",
       "4  16.060  ...           1             0           0                  0   \n",
       "\n",
       "   fr_tetrazole  fr_thiazole  fr_thiocyan  fr_thiophene  fr_unbrch_alkane  \\\n",
       "0             0            0            0             0                 0   \n",
       "1             0            0            0             0                 0   \n",
       "2             0            0            0             0                 0   \n",
       "3             0            0            0             0                 0   \n",
       "4             0            0            0             0                 0   \n",
       "\n",
       "   fr_urea  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c209b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied robust scaling\n",
      "Removed 31 highly correlated features (threshold: 0.95)\n",
      "Features reduced from 196 to 165\n",
      "Final dataset shape: Training (477, 165), Test (120, 165)\n"
     ]
    }
   ],
   "source": [
    "def advanced_preprocessing(X_train, X_test, y_train, method='robust'):\n",
    "    \"\"\"\n",
    "    Advanced preprocessing with multiple scaling options and outlier handling\n",
    "    \n",
    "    Parameters:\n",
    "    - method: 'standard', 'robust', 'minmax', 'quantile'\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler, QuantileTransformer\n",
    "    \n",
    "    scalers = {\n",
    "        'standard': StandardScaler(),\n",
    "        'robust': RobustScaler(),\n",
    "        'minmax': MinMaxScaler(),\n",
    "        'quantile': QuantileTransformer(output_distribution='normal')\n",
    "    }\n",
    "    \n",
    "    scaler = scalers[method]\n",
    "    \n",
    "    # Apply scaling\n",
    "    X_train_scaled = pd.DataFrame(\n",
    "        scaler.fit_transform(X_train),\n",
    "        columns=X_train.columns,\n",
    "        index=X_train.index\n",
    "    )\n",
    "    \n",
    "    X_test_scaled = pd.DataFrame(\n",
    "        scaler.transform(X_test),\n",
    "        columns=X_test.columns,\n",
    "        index=X_test.index\n",
    "    )\n",
    "    \n",
    "    print(f\"Applied {method} scaling\")\n",
    "    return X_train_scaled, X_test_scaled, scaler\n",
    "\n",
    "def remove_highly_correlated_features(X, threshold=0.95):\n",
    "    \"\"\"\n",
    "    Remove highly correlated features using advanced correlation analysis\n",
    "    \"\"\"\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper_triangle = corr_matrix.where(\n",
    "        np.triu(np.ones(corr_matrix.shape), k=1).astype(bool)\n",
    "    )\n",
    "    \n",
    "    # Find features to drop\n",
    "    to_drop = [column for column in upper_triangle.columns \n",
    "               if any(upper_triangle[column] > threshold)]\n",
    "    \n",
    "    X_reduced = X.drop(columns=to_drop)\n",
    "    print(f\"Removed {len(to_drop)} highly correlated features (threshold: {threshold})\")\n",
    "    print(f\"Features reduced from {X.shape[1]} to {X_reduced.shape[1]}\")\n",
    "    \n",
    "    return X_reduced, to_drop\n",
    "\n",
    "# Apply advanced preprocessing\n",
    "X_train_enhanced, X_test_enhanced, scaler = advanced_preprocessing(\n",
    "    X_train, X_test, Y_train, method='robust'\n",
    ")\n",
    "\n",
    "# Remove highly correlated features\n",
    "X_train_final, dropped_features = remove_highly_correlated_features(\n",
    "    X_train_enhanced, threshold=0.95\n",
    ")\n",
    "X_test_final = X_test_enhanced.drop(columns=dropped_features)\n",
    "\n",
    "print(f\"Final dataset shape: Training {X_train_final.shape}, Test {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf99ac2",
   "metadata": {},
   "source": [
    "### Step 3: Advanced Feature Selection with Multiple Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "233f9999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble selection chose 70 features\n",
      "Top 10 most selected features:\n",
      "fr_Ar_NH                   3\n",
      "fr_NH2                     3\n",
      "fr_piperdine               3\n",
      "SlogP_VSA10                3\n",
      "fr_amide                   3\n",
      "EState_VSA4                3\n",
      "NumSaturatedCarbocycles    3\n",
      "HallKierAlpha              3\n",
      "SMR_VSA9                   3\n",
      "EState_VSA10               3\n",
      "Name: count, dtype: int64\n",
      "Final feature set shape: (477, 70)\n"
     ]
    }
   ],
   "source": [
    "class AdvancedFeatureSelector:\n",
    "    \"\"\"\n",
    "    Comprehensive feature selection using multiple methods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.selected_features = {}\n",
    "        \n",
    "    def mutual_information_selection(self, X, y, k='auto'):\n",
    "        \"\"\"Enhanced mutual information selection\"\"\"\n",
    "        if k == 'auto':\n",
    "            k = min(50, X.shape[1] // 2)  # Adaptive k selection\n",
    "            \n",
    "        mi_scores = mutual_info_classif(X, y, random_state=self.random_state)\n",
    "        feature_scores = pd.Series(mi_scores, index=X.columns).sort_values(ascending=False)\n",
    "        \n",
    "        # Select top k features\n",
    "        selected_features = feature_scores.head(k).index.tolist()\n",
    "        self.selected_features['mutual_info'] = selected_features\n",
    "        \n",
    "        return selected_features, feature_scores\n",
    "    \n",
    "    def recursive_feature_elimination(self, X, y, estimator=None):\n",
    "        \"\"\"RFECV with cross-validation\"\"\"\n",
    "        if estimator is None:\n",
    "            estimator = RandomForestClassifier(n_estimators=100, random_state=self.random_state)\n",
    "            \n",
    "        rfecv = RFECV(\n",
    "            estimator=estimator,\n",
    "            step=1,\n",
    "            cv=5,\n",
    "            scoring='roc_auc',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        rfecv.fit(X, y)\n",
    "        selected_features = X.columns[rfecv.support_].tolist()\n",
    "        self.selected_features['rfecv'] = selected_features\n",
    "        \n",
    "        return selected_features, rfecv\n",
    "    \n",
    "    def variance_threshold_selection(self, X, threshold=0.01):\n",
    "        \"\"\"Remove low variance features\"\"\"\n",
    "        from sklearn.feature_selection import VarianceThreshold\n",
    "        \n",
    "        selector = VarianceThreshold(threshold=threshold)\n",
    "        selector.fit(X)\n",
    "        selected_features = X.columns[selector.get_support()].tolist()\n",
    "        self.selected_features['variance'] = selected_features\n",
    "        \n",
    "        return selected_features, selector\n",
    "    \n",
    "    def statistical_selection(self, X, y, method='f_classif', k=50):\n",
    "        \"\"\"Statistical feature selection\"\"\"\n",
    "        from sklearn.feature_selection import f_classif, chi2\n",
    "        \n",
    "        if method == 'f_classif':\n",
    "            selector = SelectKBest(f_classif, k=k)\n",
    "        elif method == 'chi2':\n",
    "            # Ensure non-negative values for chi2\n",
    "            X_positive = X - X.min() + 1e-5\n",
    "            selector = SelectKBest(chi2, k=k)\n",
    "            X = X_positive\n",
    "            \n",
    "        selector.fit(X, y)\n",
    "        selected_features = X.columns[selector.get_support()].tolist()\n",
    "        self.selected_features['statistical'] = selected_features\n",
    "        \n",
    "        return selected_features, selector\n",
    "    \n",
    "    def ensemble_selection(self, X, y, methods=['mutual_info', 'rfecv', 'statistical']):\n",
    "        \"\"\"Combine multiple selection methods\"\"\"\n",
    "        all_selected = []\n",
    "        \n",
    "        if 'mutual_info' in methods:\n",
    "            features, _ = self.mutual_information_selection(X, y)\n",
    "            all_selected.extend(features)\n",
    "            \n",
    "        if 'rfecv' in methods:\n",
    "            features, _ = self.recursive_feature_elimination(X, y)\n",
    "            all_selected.extend(features)\n",
    "            \n",
    "        if 'statistical' in methods:\n",
    "            features, _ = self.statistical_selection(X, y)\n",
    "            all_selected.extend(features)\n",
    "            \n",
    "        # Count feature frequency\n",
    "        feature_counts = pd.Series(all_selected).value_counts()\n",
    "        \n",
    "        # Select features that appear in at least 2 methods\n",
    "        ensemble_features = feature_counts[feature_counts >= 2].index.tolist()\n",
    "        self.selected_features['ensemble'] = ensemble_features\n",
    "        \n",
    "        return ensemble_features, feature_counts\n",
    "\n",
    "# Apply advanced feature selection\n",
    "feature_selector = AdvancedFeatureSelector(random_state=42)\n",
    "\n",
    "# Run ensemble selection\n",
    "ensemble_features, feature_counts = feature_selector.ensemble_selection(\n",
    "    X_train_final, Y_train, methods=['mutual_info', 'rfecv', 'statistical']\n",
    ")\n",
    "\n",
    "print(f\"Ensemble selection chose {len(ensemble_features)} features\")\n",
    "print(f\"Top 10 most selected features:\")\n",
    "print(feature_counts.head(10))\n",
    "\n",
    "# Create final feature set\n",
    "X_train_selected = X_train_final[ensemble_features]\n",
    "X_test_selected = X_test_final[ensemble_features]\n",
    "\n",
    "print(f\"Final feature set shape: {X_train_selected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a720e",
   "metadata": {},
   "source": [
    "### Step 4: Advanced Model Development with Optuna Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b2a1e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:43,686] Using an existing study with name 'balanced_rf_optimization' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing balanced_rf...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:   5%|â–Œ         | 1/20 [00:01<00:21,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:44,811] Trial 40 finished with value: 0.7561016587002256 and parameters: {'n_estimators': 365, 'max_depth': 23, 'min_samples_split': 9, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  10%|â–ˆ         | 2/20 [00:02<00:21,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:46,067] Trial 41 finished with value: 0.7706543646074315 and parameters: {'n_estimators': 423, 'max_depth': 11, 'min_samples_split': 12, 'min_samples_leaf': 3, 'max_features': 0.7}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  15%|â–ˆâ–Œ        | 3/20 [00:03<00:20,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:47,227] Trial 42 finished with value: 0.7761980104344234 and parameters: {'n_estimators': 418, 'max_depth': 11, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 0.7}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  20%|â–ˆâ–ˆ        | 4/20 [00:04<00:16,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:47,986] Trial 43 finished with value: 0.7601862025572432 and parameters: {'n_estimators': 449, 'max_depth': 14, 'min_samples_split': 14, 'min_samples_leaf': 4, 'max_features': 0.7}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:04<00:13,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:48,644] Trial 44 finished with value: 0.764828361065712 and parameters: {'n_estimators': 403, 'max_depth': 9, 'min_samples_split': 16, 'min_samples_leaf': 2, 'max_features': 0.7}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:05<00:10,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:49,164] Trial 45 finished with value: 0.7683612083937699 and parameters: {'n_estimators': 314, 'max_depth': 7, 'min_samples_split': 13, 'min_samples_leaf': 3, 'max_features': 0.7}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:05<00:08,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:49,597] Trial 46 finished with value: 0.7342674307521253 and parameters: {'n_estimators': 348, 'max_depth': 16, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': 'sqrt'}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:06<00:06,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:49,896] Trial 47 finished with value: 0.7757295242659242 and parameters: {'n_estimators': 163, 'max_depth': 13, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 0.7}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:06<00:05,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:50,206] Trial 48 finished with value: 0.7653505376666666 and parameters: {'n_estimators': 177, 'max_depth': 15, 'min_samples_split': 15, 'min_samples_leaf': 1, 'max_features': 0.5}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:06<00:04,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:50,578] Trial 49 finished with value: 0.7751345202646509 and parameters: {'n_estimators': 200, 'max_depth': 18, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 0.7}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 32. Best value: 0.776476:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:07<00:03,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:50,817] Trial 50 finished with value: 0.7604589275546857 and parameters: {'n_estimators': 168, 'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 'log2'}. Best is trial 32 with value: 0.7764759149028794.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:07<00:02,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:51,172] Trial 51 finished with value: 0.7829742420445939 and parameters: {'n_estimators': 187, 'max_depth': 19, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 0.7}. Best is trial 51 with value: 0.7829742420445939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:07<00:02,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:51,577] Trial 52 finished with value: 0.7790575294294797 and parameters: {'n_estimators': 219, 'max_depth': 21, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 0.7}. Best is trial 51 with value: 0.7829742420445939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:08<00:02,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:51,953] Trial 53 finished with value: 0.7770926811039597 and parameters: {'n_estimators': 206, 'max_depth': 22, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 0.7}. Best is trial 51 with value: 0.7829742420445939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:08<00:01,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:52,198] Trial 54 finished with value: 0.7703187241095982 and parameters: {'n_estimators': 116, 'max_depth': 23, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 0.7}. Best is trial 51 with value: 0.7829742420445939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:08<00:01,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:52,621] Trial 55 finished with value: 0.7713599052124769 and parameters: {'n_estimators': 237, 'max_depth': 25, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_features': 0.7}. Best is trial 51 with value: 0.7829742420445939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:09<00:01,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:52,940] Trial 56 finished with value: 0.7747666559997808 and parameters: {'n_estimators': 191, 'max_depth': 22, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 0.5}. Best is trial 51 with value: 0.7829742420445939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:09<00:00,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:53,232] Trial 57 finished with value: 0.7747560252252101 and parameters: {'n_estimators': 151, 'max_depth': 21, 'min_samples_split': 11, 'min_samples_leaf': 2, 'max_features': 0.7}. Best is trial 51 with value: 0.7829742420445939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:10<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:53,693] Trial 58 finished with value: 0.7675995611281432 and parameters: {'n_estimators': 254, 'max_depth': 26, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 0.7}. Best is trial 51 with value: 0.7829742420445939.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 51. Best value: 0.782974: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:10<00:00,  1.96it/s]\n",
      "[I 2025-08-16 20:48:53,938] Using an existing study with name 'xgboost_optimization' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:53,918] Trial 59 finished with value: 0.7481427916227212 and parameters: {'n_estimators': 143, 'max_depth': 19, 'min_samples_split': 12, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 51 with value: 0.7829742420445939.\n",
      "Best balanced_rf score: 0.7830\n",
      "Best balanced_rf params: {'n_estimators': 187, 'max_depth': 19, 'min_samples_split': 11, 'min_samples_leaf': 1, 'max_features': 0.7}\n",
      "Optimizing xgboost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:   5%|â–Œ         | 1/20 [00:00<00:04,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:54,153] Trial 40 finished with value: 0.6698805525615902 and parameters: {'n_estimators': 764, 'learning_rate': 0.10335034035291735, 'max_depth': 4, 'subsample': 0.7346033694891198, 'colsample_bytree': 0.9453637722522475, 'reg_alpha': 9.076647952825178, 'reg_lambda': 7.255286348540881}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  10%|â–ˆ         | 2/20 [00:00<00:04,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:54,416] Trial 41 finished with value: 0.7519497240202109 and parameters: {'n_estimators': 940, 'learning_rate': 0.13021064098726698, 'max_depth': 3, 'subsample': 0.8860717823102173, 'colsample_bytree': 0.684407032876449, 'reg_alpha': 0.4868924843565608, 'reg_lambda': 2.5914417721343153}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  15%|â–ˆâ–Œ        | 3/20 [00:00<00:03,  4.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:54,639] Trial 42 finished with value: 0.7554441278579156 and parameters: {'n_estimators': 881, 'learning_rate': 0.15335089415737546, 'max_depth': 3, 'subsample': 0.8747051944758344, 'colsample_bytree': 0.6228115785815763, 'reg_alpha': 0.36916190316031794, 'reg_lambda': 1.5012432938674918}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:01<00:03,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:54,927] Trial 43 finished with value: 0.7559854827328237 and parameters: {'n_estimators': 932, 'learning_rate': 0.13590476348186503, 'max_depth': 4, 'subsample': 0.8563356293120413, 'colsample_bytree': 0.7423117444775065, 'reg_alpha': 0.7914114206438176, 'reg_lambda': 2.949401859386044}. Best is trial 28 with value: 0.7676124729674524.\n",
      "[I 2025-08-16 20:48:55,111] Trial 44 finished with value: 0.7481907819597473 and parameters: {'n_estimators': 686, 'learning_rate': 0.16018820677074277, 'max_depth': 5, 'subsample': 0.9183737392792987, 'colsample_bytree': 0.6931856444214527, 'reg_alpha': 2.159866405584694, 'reg_lambda': 2.0542819729404003}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:01<00:02,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:55,369] Trial 45 finished with value: 0.7541725480352262 and parameters: {'n_estimators': 379, 'learning_rate': 0.11154755425405063, 'max_depth': 11, 'subsample': 0.8976932191374282, 'colsample_bytree': 0.7821773401702524, 'reg_alpha': 1.1031144520498692, 'reg_lambda': 4.599502548887239}. Best is trial 28 with value: 0.7676124729674524.\n",
      "[I 2025-08-16 20:48:55,504] Trial 46 finished with value: 0.7512914151343584 and parameters: {'n_estimators': 305, 'learning_rate': 0.18033943700313404, 'max_depth': 3, 'subsample': 0.8781705026244634, 'colsample_bytree': 0.7337835976606891, 'reg_alpha': 0.27537669656919983, 'reg_lambda': 0.39705393024338964}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:01<00:02,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:55,760] Trial 47 finished with value: 0.7430869495115308 and parameters: {'n_estimators': 851, 'learning_rate': 0.08913303467488073, 'max_depth': 4, 'subsample': 0.6062041527976908, 'colsample_bytree': 0.7643816740445362, 'reg_alpha': 1.5108640676543241, 'reg_lambda': 0.9559190607363379}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:02<00:02,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:55,986] Trial 48 finished with value: 0.7654326527260927 and parameters: {'n_estimators': 719, 'learning_rate': 0.20052038277428774, 'max_depth': 13, 'subsample': 0.9068413111625275, 'colsample_bytree': 0.6739035838784846, 'reg_alpha': 0.9857379047459555, 'reg_lambda': 3.764109032797897}. Best is trial 28 with value: 0.7676124729674524.\n",
      "[I 2025-08-16 20:48:56,179] Trial 49 finished with value: 0.7468179738531429 and parameters: {'n_estimators': 696, 'learning_rate': 0.20275405347809844, 'max_depth': 13, 'subsample': 0.8146161175070487, 'colsample_bytree': 0.6107096782175453, 'reg_alpha': 3.050810835635949, 'reg_lambda': 3.8172800236183533}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:02<00:01,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:56,336] Trial 50 finished with value: 0.728745571853629 and parameters: {'n_estimators': 636, 'learning_rate': 0.25889789248441736, 'max_depth': 14, 'subsample': 0.9119265046237728, 'colsample_bytree': 0.6428067760397875, 'reg_alpha': 4.327456111804915, 'reg_lambda': 0.0718441916695658}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:02<00:01,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:56,581] Trial 51 finished with value: 0.7483330280031225 and parameters: {'n_estimators': 733, 'learning_rate': 0.22040746024504226, 'max_depth': 13, 'subsample': 0.9367551847248284, 'colsample_bytree': 0.6728989675065828, 'reg_alpha': 0.73430220388892, 'reg_lambda': 5.2725350288792505}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:03<00:01,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:56,840] Trial 52 finished with value: 0.7553295338505654 and parameters: {'n_estimators': 774, 'learning_rate': 0.1951297226600607, 'max_depth': 11, 'subsample': 0.8561533616437544, 'colsample_bytree': 0.7029797910015944, 'reg_alpha': 0.2501497473256008, 'reg_lambda': 3.2881057064065975}. Best is trial 28 with value: 0.7676124729674524.\n",
      "[I 2025-08-16 20:48:56,977] Trial 53 finished with value: 0.7280581997378547 and parameters: {'n_estimators': 448, 'learning_rate': 0.13872509816398101, 'max_depth': 12, 'subsample': 0.9705740975282133, 'colsample_bytree': 0.6673455931658673, 'reg_alpha': 5.626660389773196, 'reg_lambda': 2.780157976968472}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:03<00:01,  4.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:57,213] Trial 54 finished with value: 0.7579035184496942 and parameters: {'n_estimators': 817, 'learning_rate': 0.16823410756019894, 'max_depth': 9, 'subsample': 0.8366015776523555, 'colsample_bytree': 0.7246721199044196, 'reg_alpha': 0.003116133063574722, 'reg_lambda': 1.7350449557212335}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:03<00:00,  4.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:57,427] Trial 55 finished with value: 0.7462675861301679 and parameters: {'n_estimators': 722, 'learning_rate': 0.14998216146914423, 'max_depth': 14, 'subsample': 0.8981109836886564, 'colsample_bytree': 0.6903645714874682, 'reg_alpha': 2.5116568211396997, 'reg_lambda': 2.2764574450358497}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:03<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:57,717] Trial 56 finished with value: 0.7515077878765898 and parameters: {'n_estimators': 896, 'learning_rate': 0.17656616480397774, 'max_depth': 12, 'subsample': 0.9334478792447326, 'colsample_bytree': 0.8584044264924123, 'reg_alpha': 0.8886002546111245, 'reg_lambda': 3.8536358305186096}. Best is trial 28 with value: 0.7676124729674524.\n",
      "[I 2025-08-16 20:48:57,891] Trial 57 finished with value: 0.7512462782887152 and parameters: {'n_estimators': 579, 'learning_rate': 0.2997951083542941, 'max_depth': 15, 'subsample': 0.9090637280765512, 'colsample_bytree': 0.8121091507313352, 'reg_alpha': 1.5684117707469425, 'reg_lambda': 1.2269581787466592}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:04<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:58,045] Trial 58 finished with value: 0.6738478759612545 and parameters: {'n_estimators': 516, 'learning_rate': 0.1163799868511694, 'max_depth': 10, 'subsample': 0.9622401767167231, 'colsample_bytree': 0.618208052207102, 'reg_alpha': 7.162330641997612, 'reg_lambda': 3.4422966596961517}. Best is trial 28 with value: 0.7676124729674524.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 28. Best value: 0.767612: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:04<00:00,  4.54it/s]\n",
      "[I 2025-08-16 20:48:58,362] Using an existing study with name 'lightgbm_optimization' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:58,331] Trial 59 finished with value: 0.7561211450969815 and parameters: {'n_estimators': 960, 'learning_rate': 0.1991362016003196, 'max_depth': 5, 'subsample': 0.8800194152972963, 'colsample_bytree': 0.7113788246053597, 'reg_alpha': 0.43731931318666895, 'reg_lambda': 1.9219661633136145}. Best is trial 28 with value: 0.7676124729674524.\n",
      "Best xgboost score: 0.7676\n",
      "Best xgboost params: {'n_estimators': 764, 'learning_rate': 0.20524881932175143, 'max_depth': 4, 'subsample': 0.8209923900556683, 'colsample_bytree': 0.6004182558703042, 'reg_alpha': 0.969628322595059, 'reg_lambda': 1.1229386647770523}\n",
      "Optimizing lightgbm...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:   5%|â–Œ         | 1/20 [00:00<00:17,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:48:59,294] Trial 40 finished with value: 0.7456990712590448 and parameters: {'n_estimators': 260, 'learning_rate': 0.13878813111399568, 'max_depth': 3, 'num_leaves': 276, 'subsample': 0.8458151991085348, 'colsample_bytree': 0.9161388535754149, 'reg_alpha': 0.5646964943916417, 'reg_lambda': 5.4098726161578945}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  10%|â–ˆ         | 2/20 [00:04<00:45,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:02,905] Trial 41 finished with value: 0.750744854194259 and parameters: {'n_estimators': 635, 'learning_rate': 0.26010320653990265, 'max_depth': 8, 'num_leaves': 156, 'subsample': 0.7556694052313638, 'colsample_bytree': 0.7352863617818275, 'reg_alpha': 0.1002867746535977, 'reg_lambda': 6.972256737555671}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  15%|â–ˆâ–Œ        | 3/20 [00:05<00:29,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:03,772] Trial 42 finished with value: 0.7438267252923237 and parameters: {'n_estimators': 610, 'learning_rate': 0.2859870370365867, 'max_depth': 8, 'num_leaves': 157, 'subsample': 0.7629557845329318, 'colsample_bytree': 0.6963231750003641, 'reg_alpha': 1.499389092437149, 'reg_lambda': 6.3055478604538155}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  20%|â–ˆâ–ˆ        | 4/20 [00:06<00:24,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:04,877] Trial 43 finished with value: 0.7500287892092812 and parameters: {'n_estimators': 472, 'learning_rate': 0.2352617533394202, 'max_depth': 10, 'num_leaves': 144, 'subsample': 0.7305878493795969, 'colsample_bytree': 0.7182950906479509, 'reg_alpha': 0.6394977045644507, 'reg_lambda': 4.332298039454928}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:07<00:19,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:05,842] Trial 44 finished with value: 0.750836711548096 and parameters: {'n_estimators': 467, 'learning_rate': 0.23784258301424455, 'max_depth': 14, 'num_leaves': 105, 'subsample': 0.7210744556369695, 'colsample_bytree': 0.7137137987680793, 'reg_alpha': 0.8135079271900929, 'reg_lambda': 3.306267945408572}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:08<00:16,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:06,867] Trial 45 finished with value: 0.7438076535369256 and parameters: {'n_estimators': 352, 'learning_rate': 0.22224458440918035, 'max_depth': 14, 'num_leaves': 109, 'subsample': 0.7351653481290746, 'colsample_bytree': 0.6533351464007665, 'reg_alpha': 0.5712706169759799, 'reg_lambda': 3.1149393320271646}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:09<00:13,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:07,560] Trial 46 finished with value: 0.7255055348743923 and parameters: {'n_estimators': 449, 'learning_rate': 0.2121201038675031, 'max_depth': 14, 'num_leaves': 96, 'subsample': 0.6863666924850793, 'colsample_bytree': 0.7125462637686515, 'reg_alpha': 2.1711247882282647, 'reg_lambda': 2.4529803687228573}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:09<00:10,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:08,070] Trial 47 finished with value: 0.5990028331258523 and parameters: {'n_estimators': 526, 'learning_rate': 0.2536411658011435, 'max_depth': 12, 'num_leaves': 140, 'subsample': 0.7058935866634473, 'colsample_bytree': 0.6822557323723427, 'reg_alpha': 6.66535639307719, 'reg_lambda': 4.330244311775689}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:10<00:10,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:09,110] Trial 48 finished with value: 0.7413674848395133 and parameters: {'n_estimators': 384, 'learning_rate': 0.18197187485608668, 'max_depth': 13, 'num_leaves': 127, 'subsample': 0.7450472137648715, 'colsample_bytree': 0.7679974185763062, 'reg_alpha': 0.8787968619946274, 'reg_lambda': 3.8728359887405115}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:11<00:07,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:09,541] Trial 49 finished with value: 0.5421347536315443 and parameters: {'n_estimators': 458, 'learning_rate': 0.20365981037938688, 'max_depth': 11, 'num_leaves': 59, 'subsample': 0.7147356707313783, 'colsample_bytree': 0.6376806021556689, 'reg_alpha': 9.268429296792046, 'reg_lambda': 3.1797219296746757}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:12<00:08,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:10,951] Trial 50 finished with value: 0.7478799053410677 and parameters: {'n_estimators': 305, 'learning_rate': 0.2369094562162869, 'max_depth': 10, 'num_leaves': 155, 'subsample': 0.973788080244512, 'colsample_bytree': 0.7297060116751697, 'reg_alpha': 0.3787623919021263, 'reg_lambda': 4.725489553975338}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:13<00:08,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:12,306] Trial 51 finished with value: 0.7527141126346979 and parameters: {'n_estimators': 299, 'learning_rate': 0.2299736378763973, 'max_depth': 10, 'num_leaves': 157, 'subsample': 0.9856055562679132, 'colsample_bytree': 0.7213870281341387, 'reg_alpha': 0.4045034860124143, 'reg_lambda': 3.9765063153055866}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:14<00:06,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:12,842] Trial 52 finished with value: 0.7508802945847617 and parameters: {'n_estimators': 291, 'learning_rate': 0.23267744756139294, 'max_depth': 11, 'num_leaves': 111, 'subsample': 0.9532180332970788, 'colsample_bytree': 0.7046314487643761, 'reg_alpha': 1.0910319444072822, 'reg_lambda': 0.0885459843374603}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:15<00:05,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:13,632] Trial 53 finished with value: 0.7450271041986826 and parameters: {'n_estimators': 229, 'learning_rate': 0.15636714006760855, 'max_depth': 11, 'num_leaves': 114, 'subsample': 0.9619031655368444, 'colsample_bytree': 0.7041113781124764, 'reg_alpha': 0.9115166155994587, 'reg_lambda': 1.5577762819989274}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:15<00:03,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:14,116] Trial 54 finished with value: 0.7524721214075707 and parameters: {'n_estimators': 149, 'learning_rate': 0.23041436905563145, 'max_depth': 12, 'num_leaves': 85, 'subsample': 0.9337931187958682, 'colsample_bytree': 0.6665705168165104, 'reg_alpha': 1.796277912130651, 'reg_lambda': 2.7357227878644856}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:16<00:02,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:14,453] Trial 55 finished with value: 0.712593581255494 and parameters: {'n_estimators': 104, 'learning_rate': 0.2535200342098315, 'max_depth': 12, 'num_leaves': 81, 'subsample': 0.9259308962023542, 'colsample_bytree': 0.6658720865333969, 'reg_alpha': 1.9037732466434845, 'reg_lambda': 0.19515034516453067}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:16<00:01,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:14,787] Trial 56 finished with value: 0.7165728455507788 and parameters: {'n_estimators': 148, 'learning_rate': 0.22472995532306614, 'max_depth': 13, 'num_leaves': 38, 'subsample': 0.9507639311760173, 'colsample_bytree': 0.6802266634603089, 'reg_alpha': 3.107626668229673, 'reg_lambda': 0.5615435941524733}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.756083:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:17<00:01,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:15,542] Trial 57 finished with value: 0.7489123613418824 and parameters: {'n_estimators': 282, 'learning_rate': 0.2061580358335472, 'max_depth': 13, 'num_leaves': 97, 'subsample': 0.9935396777182091, 'colsample_bytree': 0.613312123328212, 'reg_alpha': 1.1758934690391927, 'reg_lambda': 2.3995869599416686}. Best is trial 14 with value: 0.7560832698154473.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.763431:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:18<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:16,959] Trial 58 finished with value: 0.7634312692747843 and parameters: {'n_estimators': 207, 'learning_rate': 0.10361220634219925, 'max_depth': 15, 'num_leaves': 71, 'subsample': 0.9433302713240929, 'colsample_bytree': 0.7527652842516583, 'reg_alpha': 0.015561250865734233, 'reg_lambda': 1.004541398592119}. Best is trial 58 with value: 0.7634312692747843.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.763431: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:19<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:18,019] Trial 59 finished with value: 0.7340378005172781 and parameters: {'n_estimators': 176, 'learning_rate': 0.0629522221633018, 'max_depth': 14, 'num_leaves': 42, 'subsample': 0.9007639910679948, 'colsample_bytree': 0.6236573207739401, 'reg_alpha': 1.738359251731334, 'reg_lambda': 1.1919871953369754}. Best is trial 58 with value: 0.7634312692747843.\n",
      "Best lightgbm score: 0.7634\n",
      "Best lightgbm params: {'n_estimators': 207, 'learning_rate': 0.10361220634219925, 'max_depth': 15, 'num_leaves': 71, 'subsample': 0.9433302713240929, 'colsample_bytree': 0.7527652842516583, 'reg_alpha': 0.015561250865734233, 'reg_lambda': 1.004541398592119}\n",
      "\n",
      "Optimization completed!\n",
      "balanced_rf: Score = 0.7830\n",
      "xgboost: Score = 0.7676\n",
      "lightgbm: Score = 0.7634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class OptunaModelOptimizer:\n",
    "    \"\"\"\n",
    "    Advanced hyperparameter optimization using Optuna\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_trials=100, cv_folds=5, random_state=42):\n",
    "        self.n_trials = n_trials\n",
    "        self.cv_folds = cv_folds\n",
    "        self.random_state = random_state\n",
    "        self.best_params = {}\n",
    "        self.study_results = {}\n",
    "    \n",
    "    def objective_function(self, trial, model_type, X, y):\n",
    "        \"\"\"Unified objective function for all models\"\"\"\n",
    "        \n",
    "        if model_type == 'random_forest':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.5, 0.7]),\n",
    "                'random_state': self.random_state,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            model = RandomForestClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'xgboost':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "                'random_state': self.random_state,\n",
    "                'eval_metric': 'logloss',\n",
    "                'verbosity': 0\n",
    "            }\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'lightgbm':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
    "                'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "                'random_state': self.random_state,\n",
    "                'verbosity': -1,\n",
    "                'force_col_wise': True\n",
    "            }\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'catboost':\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "                'depth': trial.suggest_int('depth', 3, 10),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "                'random_state': self.random_state,\n",
    "                'verbose': False\n",
    "            }\n",
    "            model = cb.CatBoostClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'balanced_rf':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
    "                'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "                'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "                'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', 0.5, 0.7]),\n",
    "                'random_state': self.random_state,\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            model = BalancedRandomForestClassifier(**params)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        scores = cross_validate(\n",
    "            model, X, y, \n",
    "            cv=cv, \n",
    "            scoring=['roc_auc', 'accuracy', 'f1'],\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        # Return weighted score (prioritize AUC and F1)\n",
    "        return 0.5 * scores['test_roc_auc'].mean() + 0.3 * scores['test_f1'].mean() + 0.2 * scores['test_accuracy'].mean()\n",
    "    \n",
    "    def optimize_model(self, model_type, X, y):\n",
    "        \"\"\"Optimize a specific model type\"\"\"\n",
    "        print(f\"Optimizing {model_type}...\")\n",
    "\n",
    "        # Create or load Optuna study\n",
    "        study_name = f\"{model_type}_optimization\"\n",
    "        storage_name = f'optuna_{model_type}.db'\n",
    "        study = optuna.create_study(\n",
    "                direction='maximize',\n",
    "                sampler=TPESampler(seed=self.random_state),\n",
    "                study_name=study_name,\n",
    "                storage=f'sqlite:///{storage_name}',\n",
    "                load_if_exists=True\n",
    "            )\n",
    "        \n",
    "        study.optimize(\n",
    "            lambda trial: self.objective_function(trial, model_type, X, y),\n",
    "            n_trials=self.n_trials,\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        self.best_params[model_type] = study.best_params\n",
    "        self.study_results[model_type] = study\n",
    "        \n",
    "        print(f\"Best {model_type} score: {study.best_value:.4f}\")\n",
    "        print(f\"Best {model_type} params: {study.best_params}\")\n",
    "        \n",
    "        return study.best_params, study.best_value\n",
    "    \n",
    "    def optimize_all_models(self, X, y, models=['balanced_rf', 'xgboost', 'lightgbm', 'catboost']):\n",
    "        \"\"\"Optimize all specified models\"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for model_type in models:\n",
    "            params, score = self.optimize_model(model_type, X, y)\n",
    "            results[model_type] = {'params': params, 'score': score}\n",
    "            \n",
    "        return results\n",
    "\n",
    "    # Add this method to your OptunaModelOptimizer class\n",
    "    def create_optimized_models(self, optimization_results):\n",
    "        \"\"\"Create models with optimized parameters\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        for model_type, result in optimization_results.items():\n",
    "            params = result['params']\n",
    "            params['random_state'] = self.random_state\n",
    "            \n",
    "            if model_type == 'balanced_rf':\n",
    "                params['n_jobs'] = -1\n",
    "                models[model_type] = BalancedRandomForestClassifier(**params)\n",
    "            elif model_type == 'xgboost':\n",
    "                params['eval_metric'] = 'logloss'\n",
    "                params['verbosity'] = 0\n",
    "                models[model_type] = xgb.XGBClassifier(**params)\n",
    "            elif model_type == 'lightgbm':\n",
    "                params['verbosity'] = -1\n",
    "                params['force_col_wise'] = True\n",
    "                models[model_type] = lgb.LGBMClassifier(**params)\n",
    "            elif model_type == 'catboost':\n",
    "                params['verbose'] = False\n",
    "                models[model_type] = cb.CatBoostClassifier(**params)\n",
    "                \n",
    "        return models\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = OptunaModelOptimizer(n_trials=20, cv_folds=5)  # Reduce trials for demo\n",
    "\n",
    "# Optimize models (this will take some time)\n",
    "optimization_results = optimizer.optimize_all_models(\n",
    "    X_train_selected, Y_train, \n",
    "    models=['balanced_rf', 'xgboost', 'lightgbm']  # Start with these three\n",
    ")\n",
    "\n",
    "print(\"\\nOptimization completed!\")\n",
    "for model, result in optimization_results.items():\n",
    "    print(f\"{model}: Score = {result['score']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5056614c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nBest balanced_rf score: 0.7872\\nBest balanced_rf params: {'n_estimators': 145, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 0.7}\\n\\nBest xgboost score: 0.7713\\nBest xgboost params: {'n_estimators': 203, 'learning_rate': 0.18756324941006502, 'max_depth': 5, 'subsample': 0.8852212478925905, 'colsample_bytree': 0.7917396403781124, 'reg_alpha': 0.03686255734918342, 'reg_lambda': 4.805664902112656}\\n\\nBest lightgbm score: 0.7613\\nBest lightgbm params: {'n_estimators': 948, 'learning_rate': 0.29885405261154424, 'max_depth': 6, 'num_leaves': 171, 'subsample': 0.9537021727515936, 'colsample_bytree': 0.6550935656686305, 'reg_alpha': 0.9623887328034461, 'reg_lambda': 6.22836178165546}\\n\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Best balanced_rf score: 0.7872\n",
    "Best balanced_rf params: {'n_estimators': 145, 'max_depth': 6, 'min_samples_split': 7, 'min_samples_leaf': 1, 'max_features': 0.7}\n",
    "\n",
    "Best xgboost score: 0.7713\n",
    "Best xgboost params: {'n_estimators': 203, 'learning_rate': 0.18756324941006502, 'max_depth': 5, 'subsample': 0.8852212478925905, 'colsample_bytree': 0.7917396403781124, 'reg_alpha': 0.03686255734918342, 'reg_lambda': 4.805664902112656}\n",
    "\n",
    "Best lightgbm score: 0.7634\n",
    "Best lightgbm params: {'n_estimators': 207, 'learning_rate': 0.10361220634219925, 'max_depth': 15, 'num_leaves': 71, 'subsample': 0.9433302713240929, 'colsample_bytree': 0.7527652842516583, 'reg_alpha': 0.015561250865734233, 'reg_lambda': 1.004541398592119}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ba91cb",
   "metadata": {},
   "source": [
    "### Step 5: Advanced Model Ensemble and Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb5ac844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating meta-features...\n",
      "Training meta-model...\n",
      "Training base models on full data...\n",
      "Ensemble training completed!\n"
     ]
    }
   ],
   "source": [
    "class AdvancedEnsemble:\n",
    "    \"\"\"\n",
    "    Advanced ensemble methods including stacking and blending\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_models, meta_model=None, cv_folds=5, random_state=42):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model or lgb.LGBMClassifier(random_state=random_state, verbosity=-1)\n",
    "        self.cv_folds = cv_folds\n",
    "        self.random_state = random_state\n",
    "        self.trained_models = {}\n",
    "        \n",
    "    def create_optimized_models(self, optimization_results):\n",
    "        \"\"\"Create models with optimized parameters\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        for model_type, result in optimization_results.items():\n",
    "            params = result['params']\n",
    "            params['random_state'] = self.random_state\n",
    "            \n",
    "            if model_type == 'balanced_rf':\n",
    "                params['n_jobs'] = -1\n",
    "                models[model_type] = BalancedRandomForestClassifier(**params)\n",
    "            elif model_type == 'xgboost':\n",
    "                params['eval_metric'] = 'logloss'\n",
    "                params['verbosity'] = 0\n",
    "                models[model_type] = xgb.XGBClassifier(**params)\n",
    "            elif model_type == 'lightgbm':\n",
    "                params['verbosity'] = -1\n",
    "                params['force_col_wise'] = True\n",
    "                models[model_type] = lgb.LGBMClassifier(**params)\n",
    "            elif model_type == 'catboost':\n",
    "                params['verbose'] = False\n",
    "                models[model_type] = cb.CatBoostClassifier(**params)\n",
    "                \n",
    "        return models\n",
    "    \n",
    "    def stacking_cv(self, X, y):\n",
    "        \"\"\"Generate meta-features using cross-validation\"\"\"\n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "            X_train_fold = X.iloc[train_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            X_val_fold = X.iloc[val_idx]\n",
    "            \n",
    "            for i, (name, model) in enumerate(self.base_models.items()):\n",
    "                # Clone and train model\n",
    "                model_clone = clone(model)\n",
    "                model_clone.fit(X_train_fold, y_train_fold)\n",
    "                \n",
    "                # Predict on validation set\n",
    "                pred_proba = model_clone.predict_proba(X_val_fold)[:, 1]\n",
    "                meta_features[val_idx, i] = pred_proba\n",
    "                \n",
    "        return meta_features\n",
    "    \n",
    "    def fit_stacking(self, X, y):\n",
    "        \"\"\"Fit stacking ensemble\"\"\"\n",
    "        print(\"Generating meta-features...\")\n",
    "        meta_features = self.stacking_cv(X, y)\n",
    "        \n",
    "        print(\"Training meta-model...\")\n",
    "        self.meta_model.fit(meta_features, y)\n",
    "        \n",
    "        # Train base models on full data\n",
    "        print(\"Training base models on full data...\")\n",
    "        for name, model in self.base_models.items():\n",
    "            model.fit(X, y)\n",
    "            self.trained_models[name] = model\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def predict_stacking(self, X):\n",
    "        \"\"\"Predict using stacking ensemble\"\"\"\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.trained_models.items()):\n",
    "            pred_proba = model.predict_proba(X)[:, 1]\n",
    "            meta_features[:, i] = pred_proba\n",
    "            \n",
    "        return self.meta_model.predict(meta_features)\n",
    "    \n",
    "    def predict_proba_stacking(self, X):\n",
    "        \"\"\"Predict probabilities using stacking ensemble\"\"\"\n",
    "        meta_features = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.trained_models.items()):\n",
    "            pred_proba = model.predict_proba(X)[:, 1]\n",
    "            meta_features[:, i] = pred_proba\n",
    "            \n",
    "        return self.meta_model.predict_proba(meta_features)\n",
    "    \n",
    "    def weighted_average_ensemble(self, X, weights=None):\n",
    "        \"\"\"Simple weighted average ensemble\"\"\"\n",
    "        if weights is None:\n",
    "            weights = np.ones(len(self.trained_models)) / len(self.trained_models)\n",
    "            \n",
    "        predictions = np.zeros(X.shape[0])\n",
    "        \n",
    "        for i, (name, model) in enumerate(self.trained_models.items()):\n",
    "            pred_proba = model.predict_proba(X)[:, 1]\n",
    "            predictions += weights[i] * pred_proba\n",
    "            \n",
    "        return (predictions > 0.5).astype(int), predictions\n",
    "\n",
    "# Create optimized models\n",
    "optimized_models = optimizer.create_optimized_models(optimization_results)\n",
    "\n",
    "# Create ensemble\n",
    "ensemble = AdvancedEnsemble(optimized_models)\n",
    "\n",
    "# Fit stacking ensemble\n",
    "ensemble.fit_stacking(X_train_selected, Y_train)\n",
    "\n",
    "print(\"Ensemble training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051b44c5",
   "metadata": {},
   "source": [
    "### Step 6: Comprehensive Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f42ddbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating balanced_rf...\n",
      "Evaluating xgboost...\n",
      "Evaluating lightgbm...\n",
      "\n",
      "Model Comparison Results:\n",
      "               Model  CV_accuracy_mean  CV_accuracy_std  CV_precision_mean  \\\n",
      "0        balanced_rf            0.8240           0.0341             0.6459   \n",
      "1            xgboost            0.8365           0.0183             0.7685   \n",
      "2           lightgbm            0.8302           0.0165             0.7326   \n",
      "3  Stacking_Ensemble               NaN              NaN                NaN   \n",
      "\n",
      "   CV_precision_std  CV_recall_mean  CV_recall_std  CV_f1_mean  CV_f1_std  \\\n",
      "0            0.0817          0.6699         0.0649      0.6546     0.0553   \n",
      "1            0.0324          0.4833         0.0691      0.5914     0.0601   \n",
      "2            0.0627          0.5091         0.0830      0.5940     0.0542   \n",
      "3               NaN             NaN            NaN         NaN        NaN   \n",
      "\n",
      "   CV_auc_mean  ...  CV_specificity_mean  CV_specificity_std  Test_accuracy  \\\n",
      "0       0.8436  ...               0.8746              0.0394         0.8417   \n",
      "1       0.8458  ...               0.9526              0.0070         0.8417   \n",
      "2       0.8384  ...               0.9359              0.0244         0.8083   \n",
      "3          NaN  ...                  NaN                 NaN         0.8333   \n",
      "\n",
      "   Test_precision  Test_recall  Test_f1  Test_mcc  Test_auc  Test_sensitivity  \\\n",
      "0          0.7391       0.5667   0.6415    0.5500    0.8889            0.5667   \n",
      "1          0.8235       0.4667   0.5957    0.5381    0.8926            0.4667   \n",
      "2          0.7692       0.3333   0.4651    0.4180    0.8781            0.3333   \n",
      "3          0.7500       0.5000   0.6000    0.5164    0.8669            0.5000   \n",
      "\n",
      "   Test_specificity  \n",
      "0            0.9333  \n",
      "1            0.9667  \n",
      "2            0.9667  \n",
      "3            0.9444  \n",
      "\n",
      "[4 rows x 25 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "width": 3
         },
         "mode": "lines",
         "name": "balanced_rf (AUC = 0.889)",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAF2zBFmzBhj8XbMEWbMGGPxdswRZswZY/F2zBFmzBlj8RERERERGhPxEREREREaE/HMdxHMdxrD8cx3Ecx3GsPxEREREREbE/ERERERERsT8XbMEWbMG2PxdswRZswbY/mpmZmZmZuT+amZmZmZm5P5/0SZ/0Sb8/n/RJn/RJvz9VVVVVVVXFP1VVVVVVVcU/F2zBFmzBxj8XbMEWbMHGP9iCLdiCLcg/2IIt2IItyD9bsAVbsAXLP1uwBVuwBcs/HMdxHMdxzD8cx3Ecx3HMP7AFW7AFW9A/sAVbsAVb0D+amZmZmZnZP5qZmZmZmdk/W7AFW7AF2z9bsAVbsAXbPwAAAAAAAPA/",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAAARERERERGhP5qZmZmZmbk/mpmZmZmZuT/e3d3d3d3NP97d3d3d3c0/mpmZmZmZ2T+amZmZmZnZP97d3d3d3d0/3t3d3d3d3T8RERERERHhPxEREREREeE/IiIiIiIi4j8iIiIiIiLiPzMzMzMzM+M/MzMzMzMz4z9ERERERETkP0REREREROQ/VVVVVVVV5T9VVVVVVVXlP2ZmZmZmZuY/ZmZmZmZm5j+JiIiIiIjoP4mIiIiIiOg/mpmZmZmZ6T+amZmZmZnpP6uqqqqqquo/q6qqqqqq6j+8u7u7u7vrP7y7u7u7u+s/zczMzMzM7D/NzMzMzMzsP+/u7u7u7u4/7+7u7u7u7j8AAAAAAADwPwAAAAAAAPA/",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "width": 3
         },
         "mode": "lines",
         "name": "xgboost (AUC = 0.893)",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAF2zBFmzBhj8XbMEWbMGGPxdswRZswZY/F2zBFmzBlj8RERERERGhPxEREREREaE/ERERERERoT8RERERERGhPxEREREREbE/ERERERERsT+UPumTPumzP5Q+6ZM+6bM/n/RJn/RJvz+f9Emf9Em/P9InfdInfcI/0id90id9wj9VVVVVVVXFP1VVVVVVVcU/F2zBFmzBxj8XbMEWbMHGP1uwBVuwBcs/W7AFW7AFyz8cx3Ecx3HMPxzHcRzHccw/sAVbsAVb0D+wBVuwBVvQP/qkT/qkT9o/+qRP+qRP2j8AAAAAAADgPwAAAAAAAOA/AAAAAAAA8D8=",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAAARERERERGhP5qZmZmZmbk/mpmZmZmZuT9VVVVVVVXFP1VVVVVVVcU/d3d3d3d31z93d3d3d3fXP5qZmZmZmdk/3t3d3d3d3T8AAAAAAADgPwAAAAAAAOA/IiIiIiIi4j8iIiIiIiLiPzMzMzMzM+M/MzMzMzMz4z9VVVVVVVXlP1VVVVVVVeU/ZmZmZmZm5j9mZmZmZmbmP4mIiIiIiOg/iYiIiIiI6D+amZmZmZnpP5qZmZmZmek/q6qqqqqq6j+rqqqqqqrqP83MzMzMzOw/zczMzMzM7D/e3d3d3d3tP97d3d3d3e0/7+7u7u7u7j/v7u7u7u7uPwAAAAAAAPA/AAAAAAAA8D8=",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "width": 3
         },
         "mode": "lines",
         "name": "lightgbm (AUC = 0.878)",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAF2zBFmzBhj8XbMEWbMGGPxEREREREaE/ERERERERoT8XbMEWbMGmPxdswRZswaY/HMdxHMdxrD8cx3Ecx3GsPxzHcRzHcaw/HMdxHMdxrD+UPumTPumzP5Q+6ZM+6bM/n/RJn/RJvz+f9Emf9Em/PxEREREREcE/ERERERERwT/SJ33SJ33CP9InfdInfcI/F2zBFmzBxj8XbMEWbMHGP5/0SZ/0Sc8/n/RJn/RJzz8zMzMzMzPTPzMzMzMzM9M/lD7pkz7p0z+UPumTPunTP7ZgC7ZgC9Y/tmALtmAL1j93d3d3d3fXP3d3d3d3d9c/mpmZmZmZ2T+amZmZmZnZP33SJ33SJ90/fdInfdIn3T8AAAAAAADwPw==",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAAARERERERGhP5qZmZmZmbk/mpmZmZmZuT9VVVVVVVXFP1VVVVVVVcU/d3d3d3d31z93d3d3d3fXP97d3d3d3d0/3t3d3d3d3T8AAAAAAADgPyIiIiIiIuI/MzMzMzMz4z8zMzMzMzPjP0REREREROQ/RERERERE5D9VVVVVVVXlP1VVVVVVVeU/ZmZmZmZm5j9mZmZmZmbmP3d3d3d3d+c/d3d3d3d35z+JiIiIiIjoP4mIiIiIiOg/mpmZmZmZ6T+amZmZmZnpP6uqqqqqquo/q6qqqqqq6j+8u7u7u7vrP7y7u7u7u+s/zczMzMzM7D/NzMzMzMzsP97d3d3d3e0/3t3d3d3d7T/v7u7u7u7uP+/u7u7u7u4/AAAAAAAA8D8AAAAAAADwPw==",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "width": 3
         },
         "mode": "lines",
         "name": "Stacking_Ensemble (AUC = 0.867)",
         "type": "scatter",
         "x": {
          "bdata": "AAAAAAAAAAAXbMEWbMGGPxdswRZswYY/F2zBFmzBlj8XbMEWbMGWPxEREREREaE/ERERERERoT8RERERERGhPxEREREREaE/ERERERERsT8RERERERGxP5/0SZ/0Sb8/n/RJn/RJvz/SJ33SJ33CP9InfdInfcI/lD7pkz7pwz+UPumTPunDP1VVVVVVVcU/VVVVVVVVxT8XbMEWbMHGPxdswRZswcY/W7AFW7AFyz9bsAVbsAXLPxzHcRzHccw/HMdxHMdxzD/e3d3d3d3NP97d3d3d3c0/9Umf9Emf1D/1SZ/0SZ/UP7ZgC7ZgC9Y/d3d3d3d31z+amZmZmZnZP5qZmZmZmdk/AAAAAAAA4D8AAAAAAADgP8EWbMEWbOE/wRZswRZs4T8u2IIt2ILtP47jOI7jOO4/AAAAAAAA8D8=",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAABVVVVVVVXFP5qZmZmZmck/mpmZmZmZyT93d3d3d3fXP3d3d3d3d9c/mpmZmZmZ2T/e3d3d3d3dPwAAAAAAAOA/AAAAAAAA4D8RERERERHhPxEREREREeE/IiIiIiIi4j8iIiIiIiLiPzMzMzMzM+M/MzMzMzMz4z9ERERERETkP0REREREROQ/VVVVVVVV5T9VVVVVVVXlP2ZmZmZmZuY/ZmZmZmZm5j+JiIiIiIjoP4mIiIiIiOg/mpmZmZmZ6T+amZmZmZnpP7y7u7u7u+s/vLu7u7u76z/NzMzMzMzsP83MzMzMzOw/zczMzMzM7D/NzMzMzMzsP97d3d3d3e0/3t3d3d3d7T/v7u7u7u7uP+/u7u7u7u4/AAAAAAAA8D8AAAAAAADwPwAAAAAAAPA/AAAAAAAA8D8=",
          "dtype": "f8"
         }
        },
        {
         "line": {
          "color": "gray",
          "dash": "dash"
         },
         "mode": "lines",
         "name": "Random (AUC = 0.5)",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ]
        }
       ],
       "layout": {
        "height": 600,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "ROC Curves Comparison"
        },
        "width": 800,
        "xaxis": {
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "title": {
          "text": "True Positive Rate"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class ComprehensiveEvaluator:\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation with multiple metrics and visualizations\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = {}\n",
    "        \n",
    "    def calculate_metrics(self, y_true, y_pred, y_pred_proba=None):\n",
    "        \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "        from sklearn.metrics import (\n",
    "            accuracy_score, precision_score, recall_score, f1_score,\n",
    "            roc_auc_score, matthews_corrcoef, confusion_matrix,\n",
    "            classification_report\n",
    "        )\n",
    "        \n",
    "        metrics = {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred),\n",
    "            'recall': recall_score(y_true, y_pred),\n",
    "            'f1': f1_score(y_true, y_pred),\n",
    "            'mcc': matthews_corrcoef(y_true, y_pred)\n",
    "        }\n",
    "        \n",
    "        if y_pred_proba is not None:\n",
    "            metrics['auc'] = roc_auc_score(y_true, y_pred_proba)\n",
    "            \n",
    "        # Confusion matrix components\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        metrics.update({\n",
    "            'sensitivity': tp / (tp + fn),\n",
    "            'specificity': tn / (tn + fp),\n",
    "            'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn\n",
    "        })\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def cross_validation_evaluation(self, model, X, y, cv_folds=5):\n",
    "        \"\"\"Comprehensive cross-validation evaluation\"\"\"\n",
    "        cv = StratifiedKFold(n_splits=cv_folds, shuffle=True, random_state=42)\n",
    "        \n",
    "        cv_results = {\n",
    "            'accuracy': [], 'precision': [], 'recall': [], 'f1': [],\n",
    "            'auc': [], 'mcc': [], 'sensitivity': [], 'specificity': []\n",
    "        }\n",
    "        \n",
    "        for train_idx, val_idx in cv.split(X, y):\n",
    "            X_train_fold = X.iloc[train_idx]\n",
    "            y_train_fold = y.iloc[train_idx]\n",
    "            X_val_fold = X.iloc[val_idx]\n",
    "            y_val_fold = y.iloc[val_idx]\n",
    "            \n",
    "            # Train and predict\n",
    "            model_clone = clone(model)\n",
    "            model_clone.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = model_clone.predict(X_val_fold)\n",
    "            y_pred_proba = model_clone.predict_proba(X_val_fold)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            fold_metrics = self.calculate_metrics(y_val_fold, y_pred, y_pred_proba)\n",
    "            \n",
    "            for metric in cv_results:\n",
    "                if metric in fold_metrics:\n",
    "                    cv_results[metric].append(fold_metrics[metric])\n",
    "        \n",
    "        # Calculate means and stds\n",
    "        cv_summary = {}\n",
    "        for metric, values in cv_results.items():\n",
    "            cv_summary[f'{metric}_mean'] = np.mean(values)\n",
    "            cv_summary[f'{metric}_std'] = np.std(values)\n",
    "            \n",
    "        return cv_summary\n",
    "    \n",
    "    def evaluate_model(self, model, X_train, y_train, X_test, y_test, model_name):\n",
    "        \"\"\"Complete model evaluation\"\"\"\n",
    "        print(f\"Evaluating {model_name}...\")\n",
    "        \n",
    "        # Cross-validation results\n",
    "        cv_results = self.cross_validation_evaluation(model, X_train, y_train)\n",
    "        \n",
    "        # Train on full training set and test\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_test = model.predict(X_test)\n",
    "        y_pred_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        # Test set metrics\n",
    "        test_metrics = self.calculate_metrics(y_test, y_pred_test, y_pred_proba_test)\n",
    "        \n",
    "        # Store results\n",
    "        self.results[model_name] = {\n",
    "            'cv_results': cv_results,\n",
    "            'test_metrics': test_metrics,\n",
    "            'predictions': {\n",
    "                'y_pred': y_pred_test,\n",
    "                'y_pred_proba': y_pred_proba_test\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return cv_results, test_metrics\n",
    "    \n",
    "    def create_results_dataframe(self):\n",
    "        \"\"\"Create comprehensive results DataFrame\"\"\"\n",
    "        data = []\n",
    "        \n",
    "        for model_name, result in self.results.items():\n",
    "            row = {'Model': model_name}\n",
    "            \n",
    "            # Add CV results (only if they exist)\n",
    "            if 'cv_results' in result:\n",
    "                for metric, value in result['cv_results'].items():\n",
    "                    row[f'CV_{metric}'] = value\n",
    "            else:\n",
    "                # Fill with NaN for missing CV results\n",
    "                cv_metrics = ['accuracy_mean', 'accuracy_std', 'precision_mean', 'precision_std', \n",
    "                            'recall_mean', 'recall_std', 'f1_mean', 'f1_std', 'auc_mean', 'auc_std',\n",
    "                            'mcc_mean', 'mcc_std', 'sensitivity_mean', 'sensitivity_std', \n",
    "                            'specificity_mean', 'specificity_std']\n",
    "                for metric in cv_metrics:\n",
    "                    row[f'CV_{metric}'] = np.nan\n",
    "                \n",
    "            # Add test results\n",
    "            for metric, value in result['test_metrics'].items():\n",
    "                if metric not in ['tp', 'tn', 'fp', 'fn']:\n",
    "                    row[f'Test_{metric}'] = value\n",
    "                    \n",
    "            data.append(row)\n",
    "            \n",
    "        return pd.DataFrame(data)\n",
    "    \n",
    "    def plot_roc_curves(self, X_test, y_test):\n",
    "        \"\"\"Plot ROC curves for all models\"\"\"\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        for model_name, results in self.results.items():\n",
    "            y_pred_proba = results['predictions']['y_pred_proba']\n",
    "            \n",
    "            from sklearn.metrics import roc_curve\n",
    "            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "            auc_score = results['test_metrics']['auc']\n",
    "            \n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=fpr, y=tpr,\n",
    "                mode='lines',\n",
    "                name=f'{model_name} (AUC = {auc_score:.3f})',\n",
    "                line=dict(width=3)\n",
    "            ))\n",
    "        \n",
    "        # Add diagonal line\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[0, 1], y=[0, 1],\n",
    "            mode='lines',\n",
    "            name='Random (AUC = 0.5)',\n",
    "            line=dict(dash='dash', color='gray')\n",
    "        ))\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title='ROC Curves Comparison',\n",
    "            xaxis_title='False Positive Rate',\n",
    "            yaxis_title='True Positive Rate',\n",
    "            width=800, height=600\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "        \n",
    "    def plot_feature_importance(self, model, feature_names, model_name, top_n=20):\n",
    "        \"\"\"Plot feature importance\"\"\"\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            importances = model.feature_importances_\n",
    "        elif hasattr(model, 'coef_'):\n",
    "            importances = np.abs(model.coef_[0])\n",
    "        else:\n",
    "            print(f\"Cannot extract feature importance for {model_name}\")\n",
    "            return\n",
    "            \n",
    "        feature_imp = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importances\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        top_features = feature_imp.head(top_n)\n",
    "        \n",
    "        fig = px.bar(\n",
    "            top_features.iloc[::-1],  # Reverse for better visualization\n",
    "            x='importance',\n",
    "            y='feature',\n",
    "            orientation='h',\n",
    "            title=f'Top {top_n} Feature Importances - {model_name}'\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(height=600)\n",
    "        fig.show()\n",
    "\n",
    "# Evaluate individual models\n",
    "evaluator = ComprehensiveEvaluator()\n",
    "\n",
    "# Evaluate optimized models\n",
    "for model_name, model in optimized_models.items():\n",
    "    evaluator.evaluate_model(\n",
    "        model, X_train_selected, Y_train, X_test_selected, Y_test, model_name\n",
    "    )\n",
    "\n",
    "# Evaluate ensemble\n",
    "ensemble_pred = ensemble.predict_stacking(X_test_selected)\n",
    "ensemble_pred_proba = ensemble.predict_proba_stacking(X_test_selected)[:, 1]\n",
    "\n",
    "# Add ensemble results manually\n",
    "ensemble_test_metrics = evaluator.calculate_metrics(Y_test, ensemble_pred, ensemble_pred_proba)\n",
    "\n",
    "# # cross-validate ensemble\n",
    "# cv_results = evaluator.cross_validation_evaluation(ensemble, X_train_selected, Y_train)\n",
    "\n",
    "evaluator.results['Stacking_Ensemble'] = {\n",
    "    # 'cv_results': cv_results,\n",
    "    'test_metrics': ensemble_test_metrics,\n",
    "    'predictions': {\n",
    "        'y_pred': ensemble_pred,\n",
    "        'y_pred_proba': ensemble_pred_proba\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create results summary\n",
    "results_df = evaluator.create_results_dataframe()\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Plot ROC curves\n",
    "evaluator.plot_roc_curves(X_test_selected, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8e0705",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef7729ab",
   "metadata": {},
   "source": [
    "# Advancement for Higher Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dd18c6",
   "metadata": {},
   "source": [
    "### Step 7: Advanced Techniques for Higher Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6908e2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating polynomial features for top 15 features\n",
      "Enhanced features: 190 (added 120 polynomial features)\n"
     ]
    }
   ],
   "source": [
    "### Advanced Feature Engineering and Selection\n",
    "\n",
    "# 1. Polynomial Features for Selected Important Features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "def create_polynomial_features(X_train, X_test, top_features, degree=2):\n",
    "    \"\"\"Create polynomial features for most important features\"\"\"\n",
    "    # Select top features from best model\n",
    "    best_model_name = results_df.loc[results_df['Test_auc'].idxmax(), 'Model']\n",
    "    best_model = optimized_models[best_model_name]\n",
    "    \n",
    "    if hasattr(best_model, 'feature_importances_'):\n",
    "        importances = best_model.feature_importances_\n",
    "        top_idx = np.argsort(importances)[-top_features:]\n",
    "        selected_cols = X_train.columns[top_idx]\n",
    "    else:\n",
    "        # Use top features from mutual information\n",
    "        selected_cols = X_train.columns[:top_features]\n",
    "    \n",
    "    print(f\"Creating polynomial features for top {len(selected_cols)} features\")\n",
    "    \n",
    "    # Create polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, interaction_only=True, include_bias=False)\n",
    "    \n",
    "    X_train_poly = poly.fit_transform(X_train[selected_cols])\n",
    "    X_test_poly = poly.transform(X_test[selected_cols])\n",
    "    \n",
    "    # Get feature names\n",
    "    poly_names = poly.get_feature_names_out(selected_cols)\n",
    "    \n",
    "    # Convert back to DataFrame\n",
    "    X_train_poly_df = pd.DataFrame(X_train_poly, columns=poly_names, index=X_train.index)\n",
    "    X_test_poly_df = pd.DataFrame(X_test_poly, columns=poly_names, index=X_test.index)\n",
    "    \n",
    "    # Combine with original features\n",
    "    X_train_enhanced = pd.concat([X_train, X_train_poly_df], axis=1)\n",
    "    X_test_enhanced = pd.concat([X_test, X_test_poly_df], axis=1)\n",
    "    \n",
    "    print(f\"Enhanced features: {X_train_enhanced.shape[1]} (added {X_train_poly_df.shape[1]} polynomial features)\")\n",
    "    \n",
    "    return X_train_enhanced, X_test_enhanced\n",
    "\n",
    "# Create polynomial features\n",
    "X_train_poly, X_test_poly = create_polynomial_features(\n",
    "    X_train_selected, X_test_selected, top_features=15, degree=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "caa7e9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After variance filtering: 166 features\n",
      "RFECV selected 46 features\n",
      "Optimal number of features: 46\n"
     ]
    }
   ],
   "source": [
    "# 2. Advanced Feature Selection with Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def advanced_feature_selection_v2(X_train, X_test, y_train):\n",
    "    \"\"\"More aggressive feature selection\"\"\"\n",
    "    \n",
    "    # Remove low variance features more aggressively\n",
    "    from sklearn.feature_selection import VarianceThreshold\n",
    "    var_selector = VarianceThreshold(threshold=0.05)  # More aggressive\n",
    "    X_train_var = var_selector.fit_transform(X_train)\n",
    "    X_test_var = var_selector.transform(X_test)\n",
    "    \n",
    "    var_features = X_train.columns[var_selector.get_support()]\n",
    "    X_train_var_df = pd.DataFrame(X_train_var, columns=var_features, index=X_train.index)\n",
    "    X_test_var_df = pd.DataFrame(X_test_var, columns=var_features, index=X_test.index)\n",
    "    \n",
    "    print(f\"After variance filtering: {X_train_var_df.shape[1]} features\")\n",
    "    \n",
    "    # Use XGBoost for feature selection (often better than RF)\n",
    "    xgb_selector = xgb.XGBClassifier(\n",
    "        n_estimators=100, \n",
    "        random_state=42, \n",
    "        eval_metric='logloss',\n",
    "        verbosity=0\n",
    "    )\n",
    "    \n",
    "    # RFECV with XGBoost\n",
    "    rfecv = RFECV(\n",
    "        estimator=xgb_selector,\n",
    "        step=5,  # Remove 5 features at a time\n",
    "        cv=5,\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        min_features_to_select=30  # Minimum features to keep\n",
    "    )\n",
    "    \n",
    "    rfecv.fit(X_train_var_df, y_train)\n",
    "    \n",
    "    selected_features = var_features[rfecv.support_]\n",
    "    X_train_selected = X_train_var_df[selected_features]\n",
    "    X_test_selected = X_test_var_df[selected_features]\n",
    "    \n",
    "    print(f\"RFECV selected {len(selected_features)} features\")\n",
    "    print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "    \n",
    "    return X_train_selected, X_test_selected, selected_features\n",
    "\n",
    "# Apply advanced feature selection\n",
    "X_train_final_v2, X_test_final_v2, final_features = advanced_feature_selection_v2(\n",
    "    X_train_poly, X_test_poly, Y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d4002217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting DataFrame indices...\n",
      "Data shapes after reset: X_train: (477, 49), X_test: (120, 49), Y_train: 477\n",
      "Optimizing xgboost_v2 with enhanced parameters...\n",
      "Found existing study: xgboost_v2_optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:   5%|â–Œ         | 1/20 [00:03<01:12,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:38,217] Trial 40 finished with value: 0.7978597531242204 and parameters: {'n_estimators': 1598, 'learning_rate': 0.009624344711169207, 'max_depth': 3, 'min_child_weight': 6, 'subsample': 0.8486960438146444, 'colsample_bytree': 0.9071139263432786, 'colsample_bylevel': 0.7860789779281987, 'reg_alpha': 4.340125228657158, 'reg_lambda': 1.80490434363234, 'gamma': 0.44679319787014754}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  10%|â–ˆ         | 2/20 [00:08<01:12,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:42,441] Trial 41 finished with value: 0.8240199247011862 and parameters: {'n_estimators': 1820, 'learning_rate': 0.01607494476000965, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9366799116757838, 'colsample_bytree': 0.9510091249042728, 'colsample_bylevel': 0.7474270990995993, 'reg_alpha': 1.4989131734406675, 'reg_lambda': 4.9411488478510295, 'gamma': 0.8199138640738364}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  15%|â–ˆâ–Œ        | 3/20 [00:11<01:06,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:46,214] Trial 42 finished with value: 0.8173303508652559 and parameters: {'n_estimators': 1684, 'learning_rate': 0.016272231991282946, 'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.9301471344073848, 'colsample_bytree': 0.9525759308665354, 'colsample_bylevel': 0.7531148082934542, 'reg_alpha': 2.0168708473329096, 'reg_lambda': 4.548169169044528, 'gamma': 0.8369353695062623}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  20%|â–ˆâ–ˆ        | 4/20 [00:19<01:24,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:49:53,588] Trial 43 finished with value: 0.8309025651493502 and parameters: {'n_estimators': 1908, 'learning_rate': 0.009838856491004924, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9711825404980207, 'colsample_bytree': 0.9362814173803287, 'colsample_bylevel': 0.7786967026102976, 'reg_alpha': 1.4943898050714701, 'reg_lambda': 5.296406619611679, 'gamma': 0.24357860175418555}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:25<01:26,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:00,133] Trial 44 finished with value: 0.8201279739629405 and parameters: {'n_estimators': 1899, 'learning_rate': 0.009772168365195682, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9793104306067941, 'colsample_bytree': 0.8769889365774267, 'colsample_bylevel': 0.8459256559147132, 'reg_alpha': 2.9784091409552738, 'reg_lambda': 5.514554298601058, 'gamma': 0.13006531236813623}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:31<01:22,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:06,226] Trial 45 finished with value: 0.8254572928715611 and parameters: {'n_estimators': 1736, 'learning_rate': 0.0059408295713598205, 'max_depth': 4, 'min_child_weight': 2, 'subsample': 0.9660544450766388, 'colsample_bytree': 0.9326983993787773, 'colsample_bylevel': 0.7750829368199087, 'reg_alpha': 2.2768263469156476, 'reg_lambda': 6.062726006657568, 'gamma': 0.2743271293481951}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:36<01:10,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:10,680] Trial 46 finished with value: 0.8184446655780091 and parameters: {'n_estimators': 1331, 'learning_rate': 0.006545493207998033, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9970578706532582, 'colsample_bytree': 0.9357344674906678, 'colsample_bylevel': 0.7857952775068974, 'reg_alpha': 2.337424666119528, 'reg_lambda': 5.935965790572935, 'gamma': 0.29201820417351854}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:41<01:05,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:16,265] Trial 47 finished with value: 0.834088447755778 and parameters: {'n_estimators': 1738, 'learning_rate': 0.005773325584768018, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.9636383332470989, 'colsample_bytree': 0.9299579436672746, 'colsample_bylevel': 0.8098123211455714, 'reg_alpha': 0.704271072813108, 'reg_lambda': 6.016226903626196, 'gamma': 0.5533702048246028}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:46<00:56,  5.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:20,692] Trial 48 finished with value: 0.835982187407861 and parameters: {'n_estimators': 1457, 'learning_rate': 0.00814751656105649, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9600816875177612, 'colsample_bytree': 0.8796669512301063, 'colsample_bylevel': 0.8133612386944844, 'reg_alpha': 1.082855500680737, 'reg_lambda': 5.230171268925546, 'gamma': 0.5244462340938914}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:49<00:46,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:24,319] Trial 49 finished with value: 0.8296515303576694 and parameters: {'n_estimators': 1450, 'learning_rate': 0.008226464440765559, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.9797706628466141, 'colsample_bytree': 0.9113545320136074, 'colsample_bylevel': 0.8250269147976185, 'reg_alpha': 0.6738868388172811, 'reg_lambda': 5.130652606787932, 'gamma': 1.1534927722771329}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:54<00:41,  4.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:28,748] Trial 50 finished with value: 0.8377045485473225 and parameters: {'n_estimators': 1418, 'learning_rate': 0.008012519694607995, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.983333453699027, 'colsample_bytree': 0.9072047563746894, 'colsample_bylevel': 0.7986332538647494, 'reg_alpha': 0.7488849401898565, 'reg_lambda': 5.328409675563343, 'gamma': 0.5208597145273124}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:58<00:36,  4.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:33,241] Trial 51 finished with value: 0.838653438343426 and parameters: {'n_estimators': 1426, 'learning_rate': 0.008587062090861476, 'max_depth': 3, 'min_child_weight': 3, 'subsample': 0.985194797317823, 'colsample_bytree': 0.9082270124163133, 'colsample_bylevel': 0.8014725529732711, 'reg_alpha': 0.6375776526465202, 'reg_lambda': 5.326072782798781, 'gamma': 0.4849439808622817}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:02<00:29,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:36,761] Trial 52 finished with value: 0.8337763092241046 and parameters: {'n_estimators': 1330, 'learning_rate': 0.010452692266862835, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.988078170077593, 'colsample_bytree': 0.8764154760144002, 'colsample_bylevel': 0.8054092810373709, 'reg_alpha': 1.0490776257328882, 'reg_lambda': 5.284816323148881, 'gamma': 0.5485942791033092}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [01:05<00:23,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:40,170] Trial 53 finished with value: 0.8380095994647434 and parameters: {'n_estimators': 1198, 'learning_rate': 0.011435276862603832, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.9878890120907502, 'colsample_bytree': 0.8801666149918443, 'colsample_bylevel': 0.7967535983509877, 'reg_alpha': 0.48207937841742, 'reg_lambda': 4.3384711030347365, 'gamma': 0.5869975644588814}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [01:09<00:19,  3.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:44,064] Trial 54 finished with value: 0.8399650722369645 and parameters: {'n_estimators': 1197, 'learning_rate': 0.00822370919700981, 'max_depth': 3, 'min_child_weight': 1, 'subsample': 0.9612279782689885, 'colsample_bytree': 0.9028568821729006, 'colsample_bylevel': 0.7977299415816208, 'reg_alpha': 0.5108633751367904, 'reg_lambda': 4.436692699242173, 'gamma': 0.00234362745284189}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.841819:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [01:11<00:13,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:45,965] Trial 55 finished with value: 0.7858059184414052 and parameters: {'n_estimators': 1177, 'learning_rate': 0.012742486890386723, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 0.9969628422957763, 'colsample_bytree': 0.8853708608959154, 'colsample_bylevel': 0.7975386653131105, 'reg_alpha': 0.5515311068059998, 'reg_lambda': 4.030807268046513, 'gamma': 4.185348710619435}. Best is trial 7 with value: 0.8418189794969495.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.841929:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [01:16<00:11,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:50,953] Trial 56 finished with value: 0.8419291210224309 and parameters: {'n_estimators': 1191, 'learning_rate': 0.008376253330168735, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.984163770722859, 'colsample_bytree': 0.9048538044078746, 'colsample_bylevel': 0.8400115749735785, 'reg_alpha': 0.2686668245446797, 'reg_lambda': 4.5802037425196485, 'gamma': 0.02287654854844914}. Best is trial 56 with value: 0.8419291210224309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.841929:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [01:21<00:08,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:50:55,954] Trial 57 finished with value: 0.8416011062348325 and parameters: {'n_estimators': 1198, 'learning_rate': 0.010773701576166975, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9782490583040195, 'colsample_bytree': 0.9017424299207322, 'colsample_bylevel': 0.8393160319192592, 'reg_alpha': 0.31688954690418525, 'reg_lambda': 4.483235933734258, 'gamma': 0.11320704321709674}. Best is trial 56 with value: 0.8419291210224309.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.843243:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [01:26<00:04,  4.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:00,898] Trial 58 finished with value: 0.8432433773332427 and parameters: {'n_estimators': 1189, 'learning_rate': 0.014204944704666236, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9765285466327456, 'colsample_bytree': 0.8960690353489539, 'colsample_bylevel': 0.8630461236701165, 'reg_alpha': 0.029034135693057267, 'reg_lambda': 4.272454247302952, 'gamma': 0.0069277025975850864}. Best is trial 58 with value: 0.8432433773332427.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 58. Best value: 0.843243: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [01:31<00:00,  4.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:05,417] Trial 59 finished with value: 0.8419336570955525 and parameters: {'n_estimators': 1091, 'learning_rate': 0.01430330602770791, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9766994315796015, 'colsample_bytree': 0.8629966977280794, 'colsample_bylevel': 0.8742905504713555, 'reg_alpha': 0.2883774386815118, 'reg_lambda': 4.604805337249147, 'gamma': 0.013329221063163822}. Best is trial 58 with value: 0.8432433773332427.\n",
      "Best xgboost_v2 AUC: 0.8432\n",
      "Best xgboost_v2 params: {'n_estimators': 1189, 'learning_rate': 0.014204944704666236, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9765285466327456, 'colsample_bytree': 0.8960690353489539, 'colsample_bylevel': 0.8630461236701165, 'reg_alpha': 0.029034135693057267, 'reg_lambda': 4.272454247302952, 'gamma': 0.0069277025975850864}\n",
      "Optimizing lightgbm_v2 with enhanced parameters...\n",
      "Found existing study: lightgbm_v2_optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:   5%|â–Œ         | 1/20 [00:01<00:20,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:06,535] Trial 40 finished with value: 0.7849147218253159 and parameters: {'n_estimators': 1330, 'learning_rate': 0.12310440477686978, 'max_depth': 3, 'num_leaves': 455, 'min_child_samples': 44, 'subsample': 0.8385091811463585, 'colsample_bytree': 0.8110393998200629, 'reg_alpha': 2.209848888015869, 'reg_lambda': 3.5675951074893035, 'min_gain_to_split': 0.4570278491242318}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  10%|â–ˆ         | 2/20 [00:01<00:16,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:07,370] Trial 41 finished with value: 0.8240838549817424 and parameters: {'n_estimators': 851, 'learning_rate': 0.1745802377655717, 'max_depth': 4, 'num_leaves': 494, 'min_child_samples': 25, 'subsample': 0.8255414295628644, 'colsample_bytree': 0.7372162746497257, 'reg_alpha': 0.5086861284828973, 'reg_lambda': 2.70221777354265, 'min_gain_to_split': 0.5528688778932098}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  15%|â–ˆâ–Œ        | 3/20 [00:02<00:16,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:08,371] Trial 42 finished with value: 0.8164280975709328 and parameters: {'n_estimators': 1159, 'learning_rate': 0.18512692773046396, 'max_depth': 5, 'num_leaves': 475, 'min_child_samples': 29, 'subsample': 0.8596377181638907, 'colsample_bytree': 0.776639442878702, 'reg_alpha': 1.5201875255081816, 'reg_lambda': 1.7609099311176089, 'min_gain_to_split': 0.6007350341314401}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  20%|â–ˆâ–ˆ        | 4/20 [00:04<00:16,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:09,464] Trial 43 finished with value: 0.8073675750153093 and parameters: {'n_estimators': 1214, 'learning_rate': 0.1992024359766368, 'max_depth': 3, 'num_leaves': 495, 'min_child_samples': 51, 'subsample': 0.8398311300660398, 'colsample_bytree': 0.7196518140990905, 'reg_alpha': 0.4156716378117423, 'reg_lambda': 2.817566423896279, 'min_gain_to_split': 0.5024623259039676}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:04<00:14,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:10,301] Trial 44 finished with value: 0.8146953885146629 and parameters: {'n_estimators': 829, 'learning_rate': 0.14291857574936728, 'max_depth': 5, 'num_leaves': 441, 'min_child_samples': 28, 'subsample': 0.813322359007422, 'colsample_bytree': 0.7580454226042543, 'reg_alpha': 0.5435687573840998, 'reg_lambda': 3.518099750805303, 'min_gain_to_split': 0.6886045126568741}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:05<00:12,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:11,138] Trial 45 finished with value: 0.7320497663922343 and parameters: {'n_estimators': 806, 'learning_rate': 0.11256042152858702, 'max_depth': 4, 'num_leaves': 466, 'min_child_samples': 89, 'subsample': 0.8604366234505285, 'colsample_bytree': 0.7386291865546555, 'reg_alpha': 2.2402927835602533, 'reg_lambda': 1.8629086040997918, 'min_gain_to_split': 0.5389662510671419}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:06<00:11,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:12,007] Trial 46 finished with value: 0.7813008890703319 and parameters: {'n_estimators': 967, 'learning_rate': 0.15186866305874255, 'max_depth': 3, 'num_leaves': 447, 'min_child_samples': 72, 'subsample': 0.892994754351547, 'colsample_bytree': 0.8769577947761467, 'reg_alpha': 1.3402768493360615, 'reg_lambda': 2.786461841716532, 'min_gain_to_split': 0.48076658877177797}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:07<00:12,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:13,322] Trial 47 finished with value: 0.8154755930915606 and parameters: {'n_estimators': 1229, 'learning_rate': 0.07745816069871785, 'max_depth': 5, 'num_leaves': 499, 'min_child_samples': 39, 'subsample': 0.8515413969698934, 'colsample_bytree': 0.8405340130834232, 'reg_alpha': 0.5435976410339475, 'reg_lambda': 4.1778738498390915, 'min_gain_to_split': 0.6182004467204003}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [00:09<00:13,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:14,929] Trial 48 finished with value: 0.8127020678823342 and parameters: {'n_estimators': 1462, 'learning_rate': 0.06157925862420463, 'max_depth': 4, 'num_leaves': 473, 'min_child_samples': 32, 'subsample': 0.824397832455759, 'colsample_bytree': 0.7171330772225282, 'reg_alpha': 1.6809239496192312, 'reg_lambda': 4.481805039557403, 'min_gain_to_split': 0.40630948970839376}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [00:13<00:19,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:18,688] Trial 49 finished with value: 0.7635758998435056 and parameters: {'n_estimators': 1400, 'learning_rate': 0.005191851369996218, 'max_depth': 3, 'num_leaves': 423, 'min_child_samples': 58, 'subsample': 0.7844678406820722, 'colsample_bytree': 0.7971547565994891, 'reg_alpha': 3.326546827874679, 'reg_lambda': 3.3775550906604472, 'min_gain_to_split': 0.3368848114524312}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [00:13<00:14,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:19,257] Trial 50 finished with value: 0.8088459095960626 and parameters: {'n_estimators': 506, 'learning_rate': 0.15758085190945054, 'max_depth': 6, 'num_leaves': 389, 'min_child_samples': 23, 'subsample': 0.8855875600644756, 'colsample_bytree': 0.7444374900586055, 'reg_alpha': 2.1201877676233205, 'reg_lambda': 5.340195401147394, 'min_gain_to_split': 0.5444946527619422}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 7. Best value: 0.842287:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [00:14<00:11,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:20,240] Trial 51 finished with value: 0.8255340517339139 and parameters: {'n_estimators': 858, 'learning_rate': 0.1188919754644089, 'max_depth': 4, 'num_leaves': 485, 'min_child_samples': 26, 'subsample': 0.8336743203373794, 'colsample_bytree': 0.7379709017341635, 'reg_alpha': 0.5004488731192829, 'reg_lambda': 2.7764597405392344, 'min_gain_to_split': 0.5507858535284547}. Best is trial 7 with value: 0.8422871164183168.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 52. Best value: 0.84495:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [00:15<00:08,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:21,109] Trial 52 finished with value: 0.8449502165974916 and parameters: {'n_estimators': 766, 'learning_rate': 0.11671917327235631, 'max_depth': 4, 'num_leaves': 437, 'min_child_samples': 18, 'subsample': 0.8684394851165458, 'colsample_bytree': 0.7322297303008563, 'reg_alpha': 0.09720361799465871, 'reg_lambda': 2.6670786533019557, 'min_gain_to_split': 0.7132178862944913}. Best is trial 52 with value: 0.8449502165974916.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 53. Best value: 0.846182:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [00:16<00:06,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:21,756] Trial 53 finished with value: 0.8461823274591186 and parameters: {'n_estimators': 626, 'learning_rate': 0.1955679189112378, 'max_depth': 3, 'num_leaves': 438, 'min_child_samples': 17, 'subsample': 0.8688515233892402, 'colsample_bytree': 0.7701740801549516, 'reg_alpha': 0.0784834992072776, 'reg_lambda': 1.5993930984695741, 'min_gain_to_split': 0.7233957634609105}. Best is trial 53 with value: 0.8461823274591186.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 53. Best value: 0.846182:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [00:17<00:04,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:22,540] Trial 54 finished with value: 0.8369242022181398 and parameters: {'n_estimators': 713, 'learning_rate': 0.129830098992241, 'max_depth': 3, 'num_leaves': 440, 'min_child_samples': 20, 'subsample': 0.8654300853033664, 'colsample_bytree': 0.7147626964506908, 'reg_alpha': 0.23695372775894857, 'reg_lambda': 1.506429443507985, 'min_gain_to_split': 0.7244532311966527}. Best is trial 53 with value: 0.8461823274591186.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 53. Best value: 0.846182:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [00:17<00:03,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:23,316] Trial 55 finished with value: 0.8425043517951509 and parameters: {'n_estimators': 637, 'learning_rate': 0.10213203251155425, 'max_depth': 3, 'num_leaves': 430, 'min_child_samples': 18, 'subsample': 0.9453522879711864, 'colsample_bytree': 0.7846994329333423, 'reg_alpha': 0.00024156159878160888, 'reg_lambda': 1.398117815529629, 'min_gain_to_split': 0.7282390540115609}. Best is trial 53 with value: 0.8461823274591186.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.851109:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [00:18<00:02,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:24,053] Trial 56 finished with value: 0.8511093533827765 and parameters: {'n_estimators': 596, 'learning_rate': 0.10616766366828562, 'max_depth': 3, 'num_leaves': 435, 'min_child_samples': 18, 'subsample': 0.9408099751164188, 'colsample_bytree': 0.7708730295926163, 'reg_alpha': 0.0518034735166127, 'reg_lambda': 1.068493188492761, 'min_gain_to_split': 0.7238500545020455}. Best is trial 56 with value: 0.8511093533827765.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.851109:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [00:20<00:02,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:26,192] Trial 57 finished with value: 0.8331212010387608 and parameters: {'n_estimators': 596, 'learning_rate': 0.006814631902571205, 'max_depth': 3, 'num_leaves': 435, 'min_child_samples': 18, 'subsample': 0.9478881286180544, 'colsample_bytree': 0.7869039005024427, 'reg_alpha': 0.04512567923441016, 'reg_lambda': 1.0748412784272352, 'min_gain_to_split': 0.7386373121276765}. Best is trial 56 with value: 0.8511093533827765.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.851109:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [00:21<00:01,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:26,920] Trial 58 finished with value: 0.825326880769318 and parameters: {'n_estimators': 750, 'learning_rate': 0.13284756400617254, 'max_depth': 4, 'num_leaves': 361, 'min_child_samples': 18, 'subsample': 0.937759880056302, 'colsample_bytree': 0.7698291892314361, 'reg_alpha': 1.2703294827507472, 'reg_lambda': 1.4426141953806084, 'min_gain_to_split': 0.9293699165626232}. Best is trial 56 with value: 0.8511093533827765.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 56. Best value: 0.851109: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:22<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:27,546] Trial 59 finished with value: 0.7347912201469688 and parameters: {'n_estimators': 720, 'learning_rate': 0.10487639129380145, 'max_depth': 3, 'num_leaves': 417, 'min_child_samples': 21, 'subsample': 0.8703946848928927, 'colsample_bytree': 0.8079898726262869, 'reg_alpha': 5.934406535283339, 'reg_lambda': 1.5665105358041624, 'min_gain_to_split': 0.6986746517209014}. Best is trial 56 with value: 0.8511093533827765.\n",
      "Best lightgbm_v2 AUC: 0.8511\n",
      "Best lightgbm_v2 params: {'n_estimators': 596, 'learning_rate': 0.10616766366828562, 'max_depth': 3, 'num_leaves': 435, 'min_child_samples': 18, 'subsample': 0.9408099751164188, 'colsample_bytree': 0.7708730295926163, 'reg_alpha': 0.0518034735166127, 'reg_lambda': 1.068493188492761, 'min_gain_to_split': 0.7238500545020455}\n",
      "Optimizing catboost_v2 with enhanced parameters...\n",
      "Found existing study: catboost_v2_optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:   5%|â–Œ         | 1/20 [00:11<03:34, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:38,833] Trial 40 finished with value: 0.859641210791318 and parameters: {'iterations': 1637, 'learning_rate': 0.016887744439027567, 'depth': 8, 'l2_leaf_reg': 1.9096612476255737, 'border_count': 107, 'bagging_temperature': 4.346032826557857, 'random_strength': 6.561570595735214}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  10%|â–ˆ         | 2/20 [00:15<02:09,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:43,216] Trial 41 finished with value: 0.8713272691705789 and parameters: {'iterations': 1094, 'learning_rate': 0.012124001159703239, 'depth': 6, 'l2_leaf_reg': 1.6230776654477503, 'border_count': 241, 'bagging_temperature': 7.965682991325959, 'random_strength': 8.46328201090728}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  15%|â–ˆâ–Œ        | 3/20 [00:20<01:44,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:48,040] Trial 42 finished with value: 0.8718774097888458 and parameters: {'iterations': 1263, 'learning_rate': 0.013612863755213077, 'depth': 6, 'l2_leaf_reg': 2.3668794050022495, 'border_count': 215, 'bagging_temperature': 7.883804899404762, 'random_strength': 8.540608945201877}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  20%|â–ˆâ–ˆ        | 4/20 [00:24<01:23,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:51,920] Trial 43 finished with value: 0.8668786572089543 and parameters: {'iterations': 1453, 'learning_rate': 0.006579462894300343, 'depth': 5, 'l2_leaf_reg': 1.3721929365176542, 'border_count': 227, 'bagging_temperature': 7.00287287126839, 'random_strength': 7.861229583441085}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [00:27<01:06,  4.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:51:54,896] Trial 44 finished with value: 0.8655344911659977 and parameters: {'iterations': 1275, 'learning_rate': 0.022921053511179092, 'depth': 5, 'l2_leaf_reg': 2.7367504774786724, 'border_count': 139, 'bagging_temperature': 8.735315668540906, 'random_strength': 9.100010150911068}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [00:38<01:34,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:52:06,071] Trial 45 finished with value: 0.8637931352203398 and parameters: {'iterations': 1814, 'learning_rate': 0.008712816087374396, 'depth': 7, 'l2_leaf_reg': 5.131964162829724, 'border_count': 242, 'bagging_temperature': 6.696686434561948, 'random_strength': 4.732385095371651}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [00:53<02:00,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:52:20,620] Trial 46 finished with value: 0.8628730920142432 and parameters: {'iterations': 812, 'learning_rate': 0.015045543456679508, 'depth': 9, 'l2_leaf_reg': 3.7213403573615684, 'border_count': 199, 'bagging_temperature': 7.5130422581528356, 'random_strength': 9.984619142446288}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [00:57<01:34,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:52:25,504] Trial 47 finished with value: 0.8679376176543967 and parameters: {'iterations': 1364, 'learning_rate': 0.017932246553079716, 'depth': 6, 'l2_leaf_reg': 3.344439227798677, 'border_count': 181, 'bagging_temperature': 5.733343462101902, 'random_strength': 8.824494575935823}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [01:03<01:19,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:52:31,193] Trial 48 finished with value: 0.8504005210813996 and parameters: {'iterations': 946, 'learning_rate': 0.1232927556464615, 'depth': 7, 'l2_leaf_reg': 9.205428001761968, 'border_count': 221, 'bagging_temperature': 9.319773871033904, 'random_strength': 3.900858051166901}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 10/20 [01:10<01:09,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:52:37,686] Trial 49 finished with value: 0.8638535216937697 and parameters: {'iterations': 1216, 'learning_rate': 0.006341589177241183, 'depth': 8, 'l2_leaf_reg': 7.632178544349049, 'border_count': 68, 'bagging_temperature': 8.347663695772438, 'random_strength': 7.487196280845241}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [01:43<02:14, 14.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:53:10,617] Trial 50 finished with value: 0.8637541533419519 and parameters: {'iterations': 1646, 'learning_rate': 0.010317151405115582, 'depth': 9, 'l2_leaf_reg': 1.6962887492288712, 'border_count': 255, 'bagging_temperature': 3.6821228168488966, 'random_strength': 8.094417978927211}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [01:47<01:32, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:53:14,650] Trial 51 finished with value: 0.8614219738722187 and parameters: {'iterations': 1822, 'learning_rate': 0.01452021684181027, 'depth': 5, 'l2_leaf_reg': 8.176118954992962, 'border_count': 117, 'bagging_temperature': 0.7369440939548063, 'random_strength': 5.013976872562152}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [01:49<01:01,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:53:16,808] Trial 52 finished with value: 0.8651339700845979 and parameters: {'iterations': 1538, 'learning_rate': 0.02036304693916969, 'depth': 4, 'l2_leaf_reg': 6.03362399135431, 'border_count': 38, 'bagging_temperature': 1.3716923494333075, 'random_strength': 2.280566809876396}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [02:48<02:23, 23.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:54:15,630] Trial 53 finished with value: 0.8471875637885283 and parameters: {'iterations': 1729, 'learning_rate': 0.009397790457933639, 'depth': 10, 'l2_leaf_reg': 7.257217552369398, 'border_count': 233, 'bagging_temperature': 0.12471914003981743, 'random_strength': 3.542713416833271}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [03:03<01:46, 21.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:54:30,712] Trial 54 finished with value: 0.8460225017577283 and parameters: {'iterations': 1912, 'learning_rate': 0.03364829367999718, 'depth': 8, 'l2_leaf_reg': 8.506619086493663, 'border_count': 133, 'bagging_temperature': 1.799779303581525, 'random_strength': 9.546632843810116}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [03:05<01:01, 15.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:54:32,923] Trial 55 finished with value: 0.8661993093828674 and parameters: {'iterations': 570, 'learning_rate': 0.027331548776359592, 'depth': 7, 'l2_leaf_reg': 9.038960076755773, 'border_count': 75, 'bagging_temperature': 2.6143999613123143, 'random_strength': 4.490614505007368}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [03:07<00:34, 11.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:54:34,935] Trial 56 finished with value: 0.8692970929441384 and parameters: {'iterations': 1327, 'learning_rate': 0.04086307472815495, 'depth': 4, 'l2_leaf_reg': 2.1559947435864344, 'border_count': 60, 'bagging_temperature': 1.1808570148136, 'random_strength': 5.563149429913079}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [03:10<00:18,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:54:38,380] Trial 57 finished with value: 0.8490810199360412 and parameters: {'iterations': 1053, 'learning_rate': 0.0978850751486101, 'depth': 6, 'l2_leaf_reg': 1.1407659579379261, 'border_count': 148, 'bagging_temperature': 4.853352056420288, 'random_strength': 9.043365644213294}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 19/20 [03:26<00:10, 10.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:54:53,583] Trial 58 finished with value: 0.8523563482343336 and parameters: {'iterations': 1436, 'learning_rate': 0.024179855106239965, 'depth': 8, 'l2_leaf_reg': 6.596364474884341, 'border_count': 246, 'bagging_temperature': 7.7548751221839725, 'random_strength': 0.8479913580282092}. Best is trial 1 with value: 0.8812619780680866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.881262: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [03:42<00:00, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-16 20:55:09,827] Trial 59 finished with value: 0.8502042650427526 and parameters: {'iterations': 505, 'learning_rate': 0.012620518589636446, 'depth': 10, 'l2_leaf_reg': 9.43726580052309, 'border_count': 217, 'bagging_temperature': 3.244865489306816, 'random_strength': 8.637763137817862}. Best is trial 1 with value: 0.8812619780680866.\n",
      "Best catboost_v2 AUC: 0.8813\n",
      "Best catboost_v2 params: {'iterations': 1800, 'learning_rate': 0.045918988705873284, 'depth': 8, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249, 'bagging_temperature': 8.324426408004218, 'random_strength': 2.1233911067827616}\n",
      "\n",
      "Advanced Optimization Results:\n",
      "xgboost_v2: AUC = 0.8432\n",
      "lightgbm_v2: AUC = 0.8511\n",
      "catboost_v2: AUC = 0.8813\n",
      "\n",
      "xgboost_v2 Study Results:\n",
      "Best AUC: 0.8432\n",
      "Best Params: {'n_estimators': 1189, 'learning_rate': 0.014204944704666236, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9765285466327456, 'colsample_bytree': 0.8960690353489539, 'colsample_bylevel': 0.8630461236701165, 'reg_alpha': 0.029034135693057267, 'reg_lambda': 4.272454247302952, 'gamma': 0.0069277025975850864}\n",
      "\n",
      "lightgbm_v2 Study Results:\n",
      "Best AUC: 0.8511\n",
      "Best Params: {'n_estimators': 596, 'learning_rate': 0.10616766366828562, 'max_depth': 3, 'num_leaves': 435, 'min_child_samples': 18, 'subsample': 0.9408099751164188, 'colsample_bytree': 0.7708730295926163, 'reg_alpha': 0.0518034735166127, 'reg_lambda': 1.068493188492761, 'min_gain_to_split': 0.7238500545020455}\n",
      "\n",
      "catboost_v2 Study Results:\n",
      "Best AUC: 0.8813\n",
      "Best Params: {'iterations': 1800, 'learning_rate': 0.045918988705873284, 'depth': 8, 'l2_leaf_reg': 1.185260448662222, 'border_count': 249, 'bagging_temperature': 8.324426408004218, 'random_strength': 2.1233911067827616}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. Advanced Hyperparameter Optimization with More Trials and Better Objectives\n",
    "class AdvancedOptunaOptimizer:\n",
    "    \"\"\"Enhanced Optuna optimizer with better objective functions\"\"\"\n",
    "    \n",
    "    def __init__(self, n_trials=200, cv_folds=5, random_state=42):\n",
    "        self.n_trials = n_trials\n",
    "        self.cv_folds = cv_folds\n",
    "        self.random_state = random_state\n",
    "        self.best_params = {}\n",
    "        self.study_results = {}\n",
    "    \n",
    "    def objective_function_v2(self, trial, model_type, X, y):\n",
    "        \"\"\"Enhanced objective function focusing on AUC\"\"\"\n",
    "        \n",
    "        if model_type == 'xgboost_v2':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "                'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.7, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1, 10),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "                'random_state': self.random_state,\n",
    "                'eval_metric': 'auc',\n",
    "                'verbosity': 0,\n",
    "                'tree_method': 'hist'\n",
    "            }\n",
    "            model = xgb.XGBClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'lightgbm_v2':\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 500, 2000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 31, 500),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "                'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1, 10),\n",
    "                'min_gain_to_split': trial.suggest_float('min_gain_to_split', 0, 1),\n",
    "                'random_state': self.random_state,\n",
    "                'verbosity': -1,\n",
    "                'force_col_wise': True,\n",
    "                'objective': 'binary',\n",
    "                'metric': 'auc'\n",
    "            }\n",
    "            model = lgb.LGBMClassifier(**params)\n",
    "            \n",
    "        elif model_type == 'catboost_v2':\n",
    "            params = {\n",
    "                'iterations': trial.suggest_int('iterations', 500, 2000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.2, log=True),\n",
    "                'depth': trial.suggest_int('depth', 4, 10),\n",
    "                'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
    "                'border_count': trial.suggest_int('border_count', 32, 255),\n",
    "                'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 10),\n",
    "                'random_strength': trial.suggest_float('random_strength', 0, 10),\n",
    "                'random_state': self.random_state,\n",
    "                'verbose': False,\n",
    "                'eval_metric': 'AUC',\n",
    "                'task_type': 'CPU'\n",
    "            }\n",
    "            model = cb.CatBoostClassifier(**params)\n",
    "        \n",
    "        # Enhanced cross-validation with stratification\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        # Convert to numpy arrays to avoid DataFrame issues\n",
    "        X_array = X.values if hasattr(X, 'values') else X\n",
    "        y_array = y.values if hasattr(y, 'values') else y\n",
    "        \n",
    "        auc_scores = []\n",
    "        for train_idx, val_idx in cv.split(X_array, y_array):\n",
    "            X_train_fold = X_array[train_idx]\n",
    "            y_train_fold = y_array[train_idx]\n",
    "            X_val_fold = X_array[val_idx]\n",
    "            y_val_fold = y_array[val_idx]\n",
    "            \n",
    "            try:\n",
    "                model_clone = clone(model)\n",
    "                model_clone.fit(X_train_fold, y_train_fold)\n",
    "                y_pred_proba = model_clone.predict_proba(X_val_fold)[:, 1]\n",
    "                auc = roc_auc_score(y_val_fold, y_pred_proba)\n",
    "                auc_scores.append(auc)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in fold: {e}\")\n",
    "                return 0.5  # Return baseline score if error occurs\n",
    "        \n",
    "        return np.mean(auc_scores) if auc_scores else 0.5\n",
    "    \n",
    "    def optimize_model_v2(self, model_type, X, y):\n",
    "        \"\"\"Optimize with focus on AUC\"\"\"\n",
    "        print(f\"Optimizing {model_type} with enhanced parameters...\")\n",
    "        \n",
    "        # Reset DataFrame indices to avoid issues\n",
    "        if hasattr(X, 'reset_index'):\n",
    "            X = X.reset_index(drop=True)\n",
    "        if hasattr(y, 'reset_index'):\n",
    "            y = y.reset_index(drop=True)\n",
    "\n",
    "        # Create or load Optuna study\n",
    "        study_name = f\"{model_type}_optimization\"\n",
    "        storage_name = f'optuna_{model_type}.db'\n",
    "        if os.path.exists(storage_name):\n",
    "            print(f\"Found existing study: {study_name}\")\n",
    "            study = optuna.load_study(\n",
    "                study_name=study_name,\n",
    "                storage=f'sqlite:///{storage_name}'\n",
    "            )\n",
    "        else:\n",
    "            study = optuna.create_study(\n",
    "                direction='maximize',\n",
    "                sampler=TPESampler(seed=self.random_state, n_startup_trials=50),\n",
    "                study_name=study_name,\n",
    "                storage=f'sqlite:///{storage_name}',\n",
    "                load_if_exists=True\n",
    "            )\n",
    "\n",
    "        try:\n",
    "            study.optimize(\n",
    "                lambda trial: self.objective_function_v2(trial, model_type, X, y),\n",
    "                n_trials=self.n_trials,\n",
    "                show_progress_bar=True\n",
    "            )\n",
    "            \n",
    "            self.best_params[model_type] = study.best_params\n",
    "            self.study_results[model_type] = study\n",
    "            \n",
    "            print(f\"Best {model_type} AUC: {study.best_value:.4f}\")\n",
    "            print(f\"Best {model_type} params: {study.best_params}\")\n",
    "            \n",
    "            return study.best_params, study.best_value\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error optimizing {model_type}: {e}\")\n",
    "            # Return default parameters if optimization fails\n",
    "            default_params = self._get_default_params(model_type)\n",
    "            return default_params, 0.5\n",
    "    \n",
    "    def _get_default_params(self, model_type):\n",
    "        \"\"\"Get default parameters for models\"\"\"\n",
    "        defaults = {\n",
    "            'xgboost_v2': {\n",
    "                'n_estimators': 1000,\n",
    "                'learning_rate': 0.1,\n",
    "                'max_depth': 6,\n",
    "                'min_child_weight': 1,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'reg_alpha': 0,\n",
    "                'reg_lambda': 1,\n",
    "                'gamma': 0\n",
    "            },\n",
    "            'lightgbm_v2': {\n",
    "                'n_estimators': 1000,\n",
    "                'learning_rate': 0.1,\n",
    "                'max_depth': 6,\n",
    "                'num_leaves': 31,\n",
    "                'min_child_samples': 20,\n",
    "                'subsample': 0.8,\n",
    "                'colsample_bytree': 0.8,\n",
    "                'reg_alpha': 0,\n",
    "                'reg_lambda': 0,\n",
    "                'min_gain_to_split': 0\n",
    "            },\n",
    "            'catboost_v2': {\n",
    "                'iterations': 1000,\n",
    "                'learning_rate': 0.1,\n",
    "                'depth': 6,\n",
    "                'l2_leaf_reg': 3,\n",
    "                'border_count': 128,\n",
    "                'bagging_temperature': 1,\n",
    "                'random_strength': 1\n",
    "            }\n",
    "        }\n",
    "        return defaults.get(model_type, {})\n",
    "\n",
    "# Reset indices of the data before optimization\n",
    "print(\"Resetting DataFrame indices...\")\n",
    "X_train_final_v2 = X_train_final_v2.reset_index(drop=True)\n",
    "X_test_final_v2 = X_test_final_v2.reset_index(drop=True)\n",
    "Y_train = Y_train.reset_index(drop=True)\n",
    "\n",
    "print(f\"Data shapes after reset: X_train: {X_train_final_v2.shape}, X_test: {X_test_final_v2.shape}, Y_train: {len(Y_train)}\")\n",
    "\n",
    "# Initialize enhanced optimizer\n",
    "advanced_optimizer = AdvancedOptunaOptimizer(n_trials=20, cv_folds=5)  # Reduce trials for testing\n",
    "\n",
    "# Optimize advanced models\n",
    "advanced_models = ['xgboost_v2', 'lightgbm_v2', 'catboost_v2']\n",
    "advanced_results = {}\n",
    "\n",
    "for model_type in advanced_models:\n",
    "    params, score = advanced_optimizer.optimize_model_v2(model_type, X_train_final_v2, Y_train)\n",
    "    advanced_results[model_type] = {'params': params, 'score': score}\n",
    "\n",
    "print(\"\\nAdvanced Optimization Results:\")\n",
    "for model, result in advanced_results.items():\n",
    "    print(f\"{model}: AUC = {result['score']:.4f}\")\n",
    "\n",
    "# current study results\n",
    "for model_type, study in advanced_optimizer.study_results.items():\n",
    "    print(f\"\\n{model_type} Study Results:\")\n",
    "    print(f\"Best AUC: {study.best_value:.4f}\")\n",
    "    print(f\"Best Params: {study.best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "815643c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nxgboost_v2 Study Results:\\nBest AUC: 0.8418\\nBest Params: {'n_estimators': 1659, 'learning_rate': 0.01040697346842838, 'max_depth': 3, 'min_child_weight': 9, 'subsample': 0.9120572031542851, 'colsample_bytree': 0.9187021504122962, 'colsample_bylevel': 0.9313811040057837, 'reg_alpha': 0.7404465173409036, 'reg_lambda': 4.226191556898454, 'gamma': 0.5793452976256486}\\n\\nlightgbm_v2 Study Results:\\nBest AUC: 0.8423\\nBest Params: {'n_estimators': 1659, 'learning_rate': 0.01040697346842838, 'max_depth': 3, 'num_leaves': 414, 'min_child_samples': 74, 'subsample': 0.9187021504122962, 'colsample_bytree': 0.9313811040057837, 'reg_alpha': 0.7404465173409036, 'reg_lambda': 4.226191556898454, 'min_gain_to_split': 0.11586905952512971}\\n\\ncatboost_v2 Study Results:\\nBest catboost_v2 AUC: 0.8911\\nBest catboost_v2 params: {'iterations': 1389, 'learning_rate': 0.005934530307791973, 'depth': 8, 'l2_leaf_reg': 2.5347171131856236, 'border_count': 46, 'bagging_temperature': 9.488855372533333, 'random_strength': 9.656320330745594}\\n\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "xgboost_v2 Study Results:\n",
    "Best AUC: 0.8432\n",
    "Best Params: {'n_estimators': 1189, 'learning_rate': 0.014204944704666236, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.9765285466327456, 'colsample_bytree': 0.8960690353489539, 'colsample_bylevel': 0.8630461236701165, 'reg_alpha': 0.029034135693057267, 'reg_lambda': 4.272454247302952, 'gamma': 0.0069277025975850864}\n",
    "\n",
    "lightgbm_v2 Study Results:\n",
    "Best AUC: 0.8511\n",
    "Best Params: {'n_estimators': 596, 'learning_rate': 0.10616766366828562, 'max_depth': 3, 'num_leaves': 435, 'min_child_samples': 18, 'subsample': 0.9408099751164188, 'colsample_bytree': 0.7708730295926163, 'reg_alpha': 0.0518034735166127, 'reg_lambda': 1.068493188492761, 'min_gain_to_split': 0.7238500545020455}\n",
    "\n",
    "catboost_v2 Study Results:\n",
    "Best catboost_v2 AUC: 0.8911\n",
    "Best catboost_v2 params: {'iterations': 1389, 'learning_rate': 0.005934530307791973, 'depth': 8, 'l2_leaf_reg': 2.5347171131856236, 'border_count': 46, 'bagging_temperature': 9.488855372533333, 'random_strength': 9.656320330745594}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "dec4f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ultra-advanced ensemble...\n",
      "Fitting weighted ensemble...\n",
      "Converting data to numpy arrays...\n",
      "Training xgboost_v2...\n",
      "xgboost_v2 CV AUC: 0.8432\n",
      "Training lightgbm_v2...\n",
      "lightgbm_v2 CV AUC: 0.8511\n",
      "Training catboost_v2...\n",
      "catboost_v2 CV AUC: 0.8531\n",
      "\n",
      "Optimal weights:\n",
      "xgboost_v2: 0.331\n",
      "lightgbm_v2: 0.334\n",
      "catboost_v2: 0.335\n",
      "Making predictions...\n",
      "\n",
      "Ultra Ensemble Results:\n",
      "AUC: 0.8363\n",
      "Accuracy: 0.7833\n",
      "F1: 0.4091\n",
      "MCC: 0.3297\n"
     ]
    }
   ],
   "source": [
    "# 4. Advanced Ensemble with Weighted Voting and Stacking - FIXED VERSION\n",
    "class UltraAdvancedEnsemble:\n",
    "    \"\"\"Ultra-advanced ensemble with multiple techniques\"\"\"\n",
    "    \n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.models = {}\n",
    "        self.weights = {}\n",
    "        self.meta_model = None\n",
    "        \n",
    "    def create_advanced_models(self, optimization_results):\n",
    "        \"\"\"Create models with advanced parameters\"\"\"\n",
    "        models = {}\n",
    "        \n",
    "        for model_type, result in optimization_results.items():\n",
    "            params = result['params'].copy()\n",
    "            params['random_state'] = self.random_state\n",
    "            \n",
    "            if model_type == 'xgboost_v2':\n",
    "                params['eval_metric'] = 'auc'\n",
    "                params['verbosity'] = 0\n",
    "                models[model_type] = xgb.XGBClassifier(**params)\n",
    "            elif model_type == 'lightgbm_v2':\n",
    "                params['verbosity'] = -1\n",
    "                params['force_col_wise'] = True\n",
    "                models[model_type] = lgb.LGBMClassifier(**params)\n",
    "            elif model_type == 'catboost_v2':\n",
    "                params['verbose'] = False\n",
    "                models[model_type] = cb.CatBoostClassifier(**params)\n",
    "                \n",
    "        return models\n",
    "    \n",
    "    def fit_weighted_ensemble(self, X, y, models):\n",
    "        \"\"\"Fit ensemble with optimal weights\"\"\"\n",
    "        from scipy.optimize import minimize\n",
    "        \n",
    "        # CRITICAL FIX: Convert to clean numpy arrays immediately\n",
    "        print(\"Converting data to numpy arrays...\")\n",
    "        X_array = X.values if hasattr(X, 'values') else X\n",
    "        y_array = y.values if hasattr(y, 'values') else y\n",
    "        \n",
    "        # Ensure clean indices for any DataFrame operations\n",
    "        if hasattr(X, 'reset_index'):\n",
    "            X = X.reset_index(drop=True)\n",
    "        if hasattr(y, 'reset_index'):\n",
    "            y = y.reset_index(drop=True)\n",
    "        \n",
    "        # Train all models\n",
    "        trained_models = {}\n",
    "        cv_scores = {}\n",
    "        \n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state)\n",
    "        \n",
    "        for name, model in models.items():\n",
    "            print(f\"Training {name}...\")\n",
    "            # Use numpy arrays for training to avoid DataFrame issues\n",
    "            model.fit(X_array, y_array)\n",
    "            trained_models[name] = model\n",
    "            \n",
    "            # Get CV scores for weighting using numpy arrays\n",
    "            scores = []\n",
    "            for train_idx, val_idx in cv.split(X_array, y_array):\n",
    "                X_train_fold = X_array[train_idx]\n",
    "                y_train_fold = y_array[train_idx]\n",
    "                X_val_fold = X_array[val_idx]\n",
    "                y_val_fold = y_array[val_idx]\n",
    "                \n",
    "                try:\n",
    "                    model_clone = clone(model)\n",
    "                    model_clone.fit(X_train_fold, y_train_fold)\n",
    "                    y_pred_proba = model_clone.predict_proba(X_val_fold)[:, 1]\n",
    "                    score = roc_auc_score(y_val_fold, y_pred_proba)\n",
    "                    scores.append(score)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in CV for {name}: {e}\")\n",
    "                    scores.append(0.5)  # Default score\n",
    "            \n",
    "            cv_scores[name] = np.mean(scores)\n",
    "            print(f\"{name} CV AUC: {cv_scores[name]:.4f}\")\n",
    "        \n",
    "        # Optimize weights based on CV performance\n",
    "        def objective(weights):\n",
    "            weights = weights / np.sum(weights)  # Normalize\n",
    "            ensemble_pred = np.zeros(len(y_array))\n",
    "            \n",
    "            try:\n",
    "                for fold, (train_idx, val_idx) in enumerate(cv.split(X_array, y_array)):\n",
    "                    X_train_fold = X_array[train_idx]\n",
    "                    y_train_fold = y_array[train_idx]\n",
    "                    X_val_fold = X_array[val_idx]\n",
    "                    y_val_fold = y_array[val_idx]\n",
    "                    \n",
    "                    fold_preds = []\n",
    "                    for i, (name, model) in enumerate(models.items()):\n",
    "                        try:\n",
    "                            model_clone = clone(model)\n",
    "                            model_clone.fit(X_train_fold, y_train_fold)\n",
    "                            pred_proba = model_clone.predict_proba(X_val_fold)[:, 1]\n",
    "                            fold_preds.append(pred_proba)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error in weight optimization for {name}: {e}\")\n",
    "                            fold_preds.append(np.full(len(y_val_fold), 0.5))\n",
    "                    \n",
    "                    if fold_preds:\n",
    "                        weighted_pred = np.average(fold_preds, axis=0, weights=weights)\n",
    "                        ensemble_pred[val_idx] = weighted_pred\n",
    "                \n",
    "                return -roc_auc_score(y_array, ensemble_pred)  # Minimize negative AUC\n",
    "            except Exception as e:\n",
    "                print(f\"Error in objective function: {e}\")\n",
    "                return 1.0  # High value to minimize\n",
    "        \n",
    "        # Initial weights based on CV scores\n",
    "        if cv_scores:\n",
    "            initial_weights = np.array([cv_scores[name] for name in models.keys()])\n",
    "            initial_weights = initial_weights / np.sum(initial_weights)\n",
    "            \n",
    "            # Optimize weights with error handling\n",
    "            try:\n",
    "                result = minimize(\n",
    "                    objective, \n",
    "                    initial_weights, \n",
    "                    method='SLSQP',\n",
    "                    bounds=[(0.1, 1.0) for _ in range(len(models))],\n",
    "                    constraints={'type': 'eq', 'fun': lambda w: np.sum(w) - 1}\n",
    "                )\n",
    "                optimal_weights = result.x / np.sum(result.x)\n",
    "            except Exception as e:\n",
    "                print(f\"Weight optimization failed: {e}\")\n",
    "                print(\"Using equal weights...\")\n",
    "                optimal_weights = np.ones(len(models)) / len(models)\n",
    "        else:\n",
    "            print(\"No CV scores available, using equal weights...\")\n",
    "            optimal_weights = np.ones(len(models)) / len(models)\n",
    "        \n",
    "        self.models = trained_models\n",
    "        self.weights = dict(zip(models.keys(), optimal_weights))\n",
    "        \n",
    "        print(\"\\nOptimal weights:\")\n",
    "        for name, weight in self.weights.items():\n",
    "            print(f\"{name}: {weight:.3f}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba_weighted(self, X):\n",
    "        \"\"\"Predict with weighted ensemble\"\"\"\n",
    "        # Convert to numpy array to avoid DataFrame issues\n",
    "        X_array = X.values if hasattr(X, 'values') else X\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            try:\n",
    "                pred_proba = model.predict_proba(X_array)[:, 1]\n",
    "                predictions.append(pred_proba * self.weights[name])\n",
    "            except Exception as e:\n",
    "                print(f\"Error predicting with {name}: {e}\")\n",
    "                predictions.append(np.full(X_array.shape[0], 0.5) * self.weights[name])\n",
    "        \n",
    "        return np.sum(predictions, axis=0)\n",
    "    \n",
    "    def predict_weighted(self, X):\n",
    "        \"\"\"Predict classes with weighted ensemble\"\"\"\n",
    "        proba = self.predict_proba_weighted(X)\n",
    "        return (proba > 0.5).astype(int)\n",
    "\n",
    "# Create and train ultra-advanced ensemble with error handling\n",
    "print(\"Creating ultra-advanced ensemble...\")\n",
    "ultra_ensemble = UltraAdvancedEnsemble(random_state=42)\n",
    "advanced_models_dict = ultra_ensemble.create_advanced_models(advanced_results)\n",
    "\n",
    "print(\"Fitting weighted ensemble...\")\n",
    "ultra_ensemble.fit_weighted_ensemble(X_train_final_v2, Y_train, advanced_models_dict)\n",
    "\n",
    "print(\"Making predictions...\")\n",
    "# Make predictions\n",
    "ultra_pred_proba = ultra_ensemble.predict_proba_weighted(X_test_final_v2)\n",
    "ultra_pred = ultra_ensemble.predict_weighted(X_test_final_v2)\n",
    "\n",
    "# Evaluate ultra ensemble\n",
    "ultra_metrics = evaluator.calculate_metrics(Y_test, ultra_pred, ultra_pred_proba)\n",
    "print(f\"\\nUltra Ensemble Results:\")\n",
    "print(f\"AUC: {ultra_metrics['auc']:.4f}\")\n",
    "print(f\"Accuracy: {ultra_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1: {ultra_metrics['f1']:.4f}\")\n",
    "print(f\"MCC: {ultra_metrics['mcc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ebbb429e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for duplicate columns...\n",
      "X_train_final_v2 duplicate columns: 3\n",
      "X_test_final_v2 duplicate columns: 3\n",
      "Fixing duplicate columns...\n",
      "Duplicate columns fixed!\n",
      "Using catboost_v2 for pseudo-labeling...\n",
      "Added 91 pseudo-labels\n",
      "Retraining with pseudo-labels...\n",
      "Converting data to numpy arrays...\n",
      "Training xgboost_v2...\n",
      "xgboost_v2 CV AUC: 0.8941\n",
      "Training lightgbm_v2...\n",
      "lightgbm_v2 CV AUC: 0.8902\n",
      "Training catboost_v2...\n",
      "catboost_v2 CV AUC: 0.8947\n",
      "\n",
      "Optimal weights:\n",
      "xgboost_v2: 0.334\n",
      "lightgbm_v2: 0.332\n",
      "catboost_v2: 0.334\n",
      "\n",
      "Final Enhanced Results:\n",
      "AUC: 0.8248\n",
      "Accuracy: 0.7833\n",
      "F1: 0.4091\n",
      "MCC: 0.3297\n"
     ]
    }
   ],
   "source": [
    "# 5. Additional Techniques: Pseudo-labeling and Data Augmentation - FIXED VERSION\n",
    "def pseudo_labeling_enhancement(X_train, y_train, X_test, best_model, confidence_threshold=0.9):\n",
    "    \"\"\"Add high-confidence predictions as pseudo-labels\"\"\"\n",
    "    \n",
    "    # CRITICAL FIX: Convert to numpy arrays to avoid column name issues\n",
    "    X_train_array = X_train.values if hasattr(X_train, 'values') else X_train\n",
    "    y_train_array = y_train.values if hasattr(y_train, 'values') else y_train\n",
    "    X_test_array = X_test.values if hasattr(X_test, 'values') else X_test\n",
    "    \n",
    "    # Train model on original data using numpy arrays\n",
    "    best_model.fit(X_train_array, y_train_array)\n",
    "    \n",
    "    # Get predictions on test set\n",
    "    test_proba = best_model.predict_proba(X_test_array)\n",
    "    \n",
    "    # Select high-confidence predictions\n",
    "    max_proba = np.max(test_proba, axis=1)\n",
    "    high_conf_mask = max_proba >= confidence_threshold\n",
    "    \n",
    "    if np.sum(high_conf_mask) > 0:\n",
    "        # Add pseudo-labels using numpy arrays\n",
    "        X_pseudo = X_test_array[high_conf_mask]\n",
    "        y_pseudo = np.argmax(test_proba[high_conf_mask], axis=1)\n",
    "        \n",
    "        # Combine with training data (numpy arrays)\n",
    "        X_enhanced = np.vstack([X_train_array, X_pseudo])\n",
    "        y_enhanced = np.concatenate([y_train_array, y_pseudo])\n",
    "        \n",
    "        print(f\"Added {len(y_pseudo)} pseudo-labels\")\n",
    "        return X_enhanced, y_enhanced\n",
    "    else:\n",
    "        print(\"No high-confidence predictions found\")\n",
    "        return X_train_array, y_train_array\n",
    "\n",
    "# Also, let's check for and fix duplicate column names in our data\n",
    "def fix_duplicate_columns(df):\n",
    "    \"\"\"Fix duplicate column names by adding suffixes\"\"\"\n",
    "    cols = pd.Series(df.columns)\n",
    "    for dup in cols[cols.duplicated()].unique():\n",
    "        cols[cols[cols == dup].index.values[1:]] = [dup + '_' + str(i) for i in range(1, sum(cols == dup))]\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "# Fix duplicate columns in our datasets\n",
    "print(\"Checking for duplicate columns...\")\n",
    "print(f\"X_train_final_v2 duplicate columns: {X_train_final_v2.columns.duplicated().sum()}\")\n",
    "print(f\"X_test_final_v2 duplicate columns: {X_test_final_v2.columns.duplicated().sum()}\")\n",
    "\n",
    "if X_train_final_v2.columns.duplicated().sum() > 0:\n",
    "    print(\"Fixing duplicate columns...\")\n",
    "    X_train_final_v2 = fix_duplicate_columns(X_train_final_v2)\n",
    "    X_test_final_v2 = fix_duplicate_columns(X_test_final_v2)\n",
    "    print(\"Duplicate columns fixed!\")\n",
    "\n",
    "# Apply pseudo-labeling with best model\n",
    "best_model_name = max(advanced_results.keys(), key=lambda x: advanced_results[x]['score'])\n",
    "best_model = advanced_models_dict[best_model_name]\n",
    "\n",
    "print(f\"Using {best_model_name} for pseudo-labeling...\")\n",
    "\n",
    "X_train_pseudo, Y_train_pseudo = pseudo_labeling_enhancement(\n",
    "    X_train_final_v2, Y_train, X_test_final_v2, best_model, confidence_threshold=0.95\n",
    ")\n",
    "\n",
    "# Retrain ultra ensemble with pseudo-labels if any were added\n",
    "if len(Y_train_pseudo) > len(Y_train):\n",
    "    print(\"Retraining with pseudo-labels...\")\n",
    "    \n",
    "    # Create new ensemble for pseudo-labeled data\n",
    "    ultra_ensemble_v2 = UltraAdvancedEnsemble(random_state=42)\n",
    "    \n",
    "    # For the ensemble, we need to use the original models but retrain them\n",
    "    # Create fresh models to avoid any state issues\n",
    "    advanced_models_dict_v2 = ultra_ensemble_v2.create_advanced_models(advanced_results)\n",
    "    \n",
    "    # Fit with pseudo-labeled data (using numpy arrays)\n",
    "    ultra_ensemble_v2.fit_weighted_ensemble(X_train_pseudo, Y_train_pseudo, advanced_models_dict_v2)\n",
    "    \n",
    "    # Final predictions\n",
    "    final_pred_proba = ultra_ensemble_v2.predict_proba_weighted(X_test_final_v2)\n",
    "    final_pred = ultra_ensemble_v2.predict_weighted(X_test_final_v2)\n",
    "    \n",
    "    final_metrics = evaluator.calculate_metrics(Y_test, final_pred, final_pred_proba)\n",
    "    print(f\"\\nFinal Enhanced Results:\")\n",
    "    print(f\"AUC: {final_metrics['auc']:.4f}\")\n",
    "    print(f\"Accuracy: {final_metrics['accuracy']:.4f}\")\n",
    "    print(f\"F1: {final_metrics['f1']:.4f}\")\n",
    "    print(f\"MCC: {final_metrics['mcc']:.4f}\")\n",
    "else:\n",
    "    final_pred_proba = ultra_pred_proba\n",
    "    final_pred = ultra_pred\n",
    "    final_metrics = ultra_metrics\n",
    "    print(\"No pseudo-labels added, using original ensemble results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calibrated Model Results:\n",
      "AUC: 0.8539\n",
      "Accuracy: 0.8083\n",
      "F1: 0.5306\n",
      "MCC: 0.4349\n"
     ]
    }
   ],
   "source": [
    "# 6. Model Calibration for Better Probability Estimates\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "def calibrate_model_predictions(model, X_train, y_train, X_test, method='isotonic'):\n",
    "    \"\"\"Calibrate model predictions for better probability estimates\"\"\"\n",
    "    \n",
    "    # Create calibrated classifier\n",
    "    calibrated_model = CalibratedClassifierCV(model, method=method, cv=5)\n",
    "    calibrated_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get calibrated predictions\n",
    "    calibrated_proba = calibrated_model.predict_proba(X_test)[:, 1]\n",
    "    calibrated_pred = calibrated_model.predict(X_test)\n",
    "    \n",
    "    return calibrated_pred, calibrated_proba\n",
    "\n",
    "# Calibrate the best individual model\n",
    "best_model_calibrated = clone(best_model)\n",
    "cal_pred, cal_pred_proba = calibrate_model_predictions(\n",
    "    best_model_calibrated, X_train_final_v2, Y_train, X_test_final_v2\n",
    ")\n",
    "\n",
    "cal_metrics = evaluator.calculate_metrics(Y_test, cal_pred, cal_pred_proba)\n",
    "print(f\"\\nCalibrated Model Results:\")\n",
    "print(f\"AUC: {cal_metrics['auc']:.4f}\")\n",
    "print(f\"Accuracy: {cal_metrics['accuracy']:.4f}\")\n",
    "print(f\"F1: {cal_metrics['f1']:.4f}\")\n",
    "print(f\"MCC: {cal_metrics['mcc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "257dce1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FINAL RESULTS COMPARISON\n",
      "==================================================\n",
      "Original Best            : AUC = 0.8926\n",
      "Calibrated Model         : AUC = 0.8539\n",
      "Ultra Ensemble           : AUC = 0.8363\n",
      "Enhanced with Pseudo-labels: AUC = 0.8248\n",
      "\n",
      "Best method: Original Best with AUC = 0.8926\n",
      "Current best AUC: 0.8926\n",
      "Consider running with more trials or trying additional techniques.\n"
     ]
    }
   ],
   "source": [
    "# 7. Final Comparison and Selection\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL RESULTS COMPARISON\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "all_results = {\n",
    "    'Original Best': results_df.loc[results_df['Test_auc'].idxmax(), 'Test_auc'],\n",
    "    'Ultra Ensemble': ultra_metrics['auc'],\n",
    "    'Calibrated Model': cal_metrics['auc'],\n",
    "}\n",
    "\n",
    "if len(Y_train_pseudo) > len(Y_train):\n",
    "    all_results['Enhanced with Pseudo-labels'] = final_metrics['auc']\n",
    "\n",
    "for method, auc in sorted(all_results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{method:25}: AUC = {auc:.4f}\")\n",
    "\n",
    "# Select best method\n",
    "best_method = max(all_results.keys(), key=lambda x: all_results[x])\n",
    "best_auc = all_results[best_method]\n",
    "\n",
    "print(f\"\\nBest method: {best_method} with AUC = {best_auc:.4f}\")\n",
    "\n",
    "if best_auc >= 0.9:\n",
    "    print(\"ðŸŽ‰ Target AUC of 0.9+ achieved!\")\n",
    "else:\n",
    "    print(f\"Current best AUC: {best_auc:.4f}\")\n",
    "    print(\"Consider running with more trials or trying additional techniques.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0734fb2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n==================================================\\nFINAL RESULTS COMPARISON\\n==================================================\\nOriginal Best            : AUC = 0.8926\\nCalibrated Model         : AUC = 0.8539\\nEnhanced with Pseudo-labels: AUC = 0.8456\\nUltra Ensemble           : AUC = 0.8430\\n\\nBest method: Original Best with AUC = 0.8926\\n'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "==================================================\n",
    "FINAL RESULTS COMPARISON\n",
    "==================================================\n",
    "Original Best            : AUC = 0.8926\n",
    "Calibrated Model         : AUC = 0.8539\n",
    "Enhanced with Pseudo-labels: AUC = 0.8456\n",
    "Ultra Ensemble           : AUC = 0.8430\n",
    "\n",
    "Best method: Original Best with AUC = 0.8926\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "03bbe69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Study Results:\n",
      "Model: balanced_rf\n",
      "Number of completed trials: 60\n",
      "Best AUC: 0.7830\n",
      "\n",
      "Study Results:\n",
      "Model: xgboost\n",
      "Number of completed trials: 60\n",
      "Best AUC: 0.7676\n",
      "\n",
      "Study Results:\n",
      "Model: lightgbm\n",
      "Number of completed trials: 60\n",
      "Best AUC: 0.7634\n"
     ]
    }
   ],
   "source": [
    "for model_name, result in optimizer.study_results.items():\n",
    "    print(\"\\nStudy Results:\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    completed = [t for t in result.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    print(f\"Number of completed trials: {len(completed)}\")\n",
    "    print(f\"Best AUC: {result.best_value:.4f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b7f87a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced Study Results:\n",
      "Model: xgboost_v2\n",
      "Number of completed trials: 60\n",
      "Best AUC: 0.8432\n",
      "\n",
      "Advanced Study Results:\n",
      "Model: lightgbm_v2\n",
      "Number of completed trials: 60\n",
      "Best AUC: 0.8511\n",
      "\n",
      "Advanced Study Results:\n",
      "Model: catboost_v2\n",
      "Number of completed trials: 60\n",
      "Best AUC: 0.8813\n"
     ]
    }
   ],
   "source": [
    "for model_name, result in advanced_optimizer.study_results.items():\n",
    "    print(\"\\nAdvanced Study Results:\")\n",
    "    print(f\"Model: {model_name}\")\n",
    "    completed = [t for t in result.trials if t.state == optuna.trial.TrialState.COMPLETE]\n",
    "    print(f\"Number of completed trials: {len(completed)}\")\n",
    "    print(f\"Best AUC: {result.best_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
